---
layout: post
title: "Megatrends in Sound: AI, Competition, and What's Next for Audio"
date: 2024-06-14
description: Reflections from the Danish Sound Cluster workshop on AI, industry challenges, and the future of audio technology
tags: [auditory-perception, career-tips]
categories: [research]
thumbnail: assets/img/posts/megatrends-sound-workshop.jpg
---

Last Friday, I found myself back at FORCE Technology in Hørsholm, a place that used to be my office during my PhD years (2019-2022). This time, though, I wasn't there as a doctoral student buried in experiments. I was attending the [**Megatrends in the Sound Industry Workshop**](https://danishsoundcluster.dk/megatrends-in-the-sound-industry/), organized by Danish Technological Institute and Danish Sound Cluster.

Walking through those familiar corridors felt surreal. The SenseLab where I spent countless hours running perceptual evaluations was still there, still buzzing with activity. But the context had shifted entirely. I was now sitting among senior professionals from EPOS, Jabra, Augmented Hearing, and other major players in Denmark's audio scene. And yes, I think I was the only Asian person in the room, which made the experience both humbling and a bit isolating in an oddly motivating way.

---

## Why I Went

To be honest, I wanted to understand **where the Danish audio industry is heading**. What are the challenges? What opportunities are hiding beneath the hype? And most importantly, how is AI reshaping an industry that's already been fundamentally redefined by digitalization over the past decade?

The workshop agenda was packed with perspectives I needed to hear:

- **Emil Højbjerre Thomsen** (Danish Technological Institute) kicked things off with the big picture: megatrends reshaping sound technology
- **Mette Vestergaard Carstensen** (Augmented Hearing) brought AI down to earth with real-world implementation experiences
- A **panel debate** featuring **Torben Christiansen** (EPOS), **Ali Gurcan Ozkil** (Jabra Voice Analytics), and **Christer P. Volk** (FORCE Technology) dissected what it actually takes to deploy AI in sound products

And of course, the optional **SenseLab tour** at the end, a nostalgic trip through the place where I learned how to bridge subjective human perception with objective measurements.

---

## The Elephant in the Room: AI Is Here, But Are We Ready?

Let's cut to the chase: **AI is both a goldmine and a minefield** for the audio industry.

On one hand, we're seeing breakthroughs that were science fiction five years ago:
- Real-time speech enhancement that adapts to individual hearing profiles
- Generative audio models that can synthesize realistic soundscapes
- Predictive algorithms that anticipate user needs before they press a button

But the workshop also exposed uncomfortable truths:

### 1. **The Data Problem**
AI models are hungry. They need massive, diverse, high-quality datasets. But in audio, especially for niche applications like hearing aids or spatial audio, **labeled data is scarce and expensive**. Mette from Augmented Hearing emphasized this hard: "You can have the best algorithm in the world, but if your training data doesn't represent your users, you're building a biased system."

This resonates deeply with my work in perceptual evaluation. We know that **human perception varies wildly** across demographics, languages, and cultural contexts. An AI trained on Western English speakers will fail spectacularly when deployed in Asian markets. Yet, how many companies are actually investing in globally representative datasets?

### 2. **The Interpretability Gap**
During the panel, Ali from Jabra raised a point that stuck with me: **"How do you explain to a user why the AI made a certain sound adjustment?"**

In perceptual audio engineering, we've always prioritized **transparency**. Users need to trust that what they're hearing is intentional, not a black-box accident. But deep learning models are notoriously opaque. When your AI-powered hearing aid suddenly amplifies background noise instead of speech, how do you debug that? How do you regain user trust?

This isn't just a technical challenge, it's a **UX and ethics problem**. We need explainable AI for audio, not just accurate AI.

### 3. **Global Competition and the "Innovate or Die" Pressure**
Here's where the conversation got uncomfortable: **Denmark is a small market**. Companies like EPOS, Jabra, and GN have global reach, but they're competing against tech giants (Apple, Google, Samsung) and aggressive Asian manufacturers who can move faster and cheaper.

The workshop didn't shy away from this. Torben from EPOS was blunt: "We can't compete on price. We have to compete on **quality, innovation, and user experience**." But innovation requires R&D investment, and R&D is expensive. The question is: **Can Danish companies sustain this model long-term?**

---

## What Struck Me: The Human Element Still Matters

Despite all the AI talk, what gave me hope was this: **Everyone in that room agreed that human perception is still the gold standard**.

Emil's opening presentation emphasized that technology trends are meaningless if they don't solve **real human problems**. Mette shared how Augmented Hearing's AI developments are grounded in **extensive user testing**. The panel debate kept circling back to one core principle: **AI should augment human experience, not replace human judgment**.

This is where my background in perceptual evaluation feels more relevant than ever. The future isn't about building the most sophisticated algorithm, it's about building systems that **truly understand how humans hear, process, and respond to sound**.

---

## My Thoughts Moving Forward

Walking out of that workshop, I felt a mix of excitement and urgency. Here's what I think needs to happen:

### 1. **Invest in Perceptual Research, Not Just AI Hype**
Companies are throwing money at AI engineers, but not enough at **perceptual scientists** who can validate whether these algorithms actually work for real users. We need more cross-disciplinary teams where AI developers and psychoacousticians work side-by-side.

### 2. **Build Open, Diverse Datasets**
The audio industry needs an equivalent of ImageNet, a massive, open-source, globally representative dataset for perceptual audio research. Without this, we'll keep building biased systems.

### 3. **Rethink Evaluation Metrics**
Objective metrics (SNR, PESQ, POLQA) are useful, but they don't capture **user satisfaction**. We need standardized frameworks for subjective evaluation that scale with AI-driven products. This is where initiatives like the [ITU-T P.800 series](https://www.itu.int/rec/T-REC-P.800) need updating for the AI era.

### 4. **Strengthen Regional Collaboration**
Denmark's audio cluster is strong, but it's also relatively small. **Cross-border partnerships**, whether with European research institutions or Asian manufacturers, are essential. Competition is global; collaboration should be too.

---

## Final Reflection: The Only Constant is Change

Returning to FORCE Technology felt like closing a chapter and opening a new one. My PhD was about understanding **how humans perceive immersive audio-visual technology**. Now, the question is: **How do we build AI systems that preserve and enhance that human experience?**

The workshop didn't provide all the answers (no single event ever does), but it sharpened the questions. And in a rapidly evolving industry, asking the right questions is half the battle.

If you're working in audio, AI, or perceptual research, I'd love to hear your thoughts. What challenges are you seeing? Where do you think the industry is headed? Let's keep this conversation going.

---

**P.S.** If you're curious about the workshop content, check out the [Danish Sound Cluster event page](https://danishsoundcluster.dk/megatrends-in-the-sound-industry/). And if you want to dive deeper into perceptual evaluation methodologies, feel free to reach out. I'm always happy to nerd out about this stuff. ☕

---

*Tags: #AudioTechnology #AI #PerceptualEvaluation #DanishSoundCluster #Research*
