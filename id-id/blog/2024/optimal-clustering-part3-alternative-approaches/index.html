<!DOCTYPE html> <html lang="id-id"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Finding the Optimal Number of Clusters: Part 3 - Alternative Approaches &amp; Practical Guide | Dr. Randy F Fela </title> <meta name="author" content="Randy F. Fela"> <meta name="description" content="Complete your clustering toolkit with dendrogram analysis, DBSCAN tuning, and a comprehensive decision framework. From theory to production-ready code."> <meta name="keywords" content="perception, audio-visual, research, data-science"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/bitmoji-closeup.png?abba4a3066d843d333ecf75654a92392"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://fransfela.github.io/blog/2024/optimal-clustering-part3-alternative-approaches/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/id-id/"> Dr. Randy F Fela </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/id-id/">üéß <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/id-id/about/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/id-id/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/id-id/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/id-id/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/id-id/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/2024/optimal-clustering-part3-alternative-approaches/"> EN-US</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Finding the Optimal Number of Clusters: Part 3 - Alternative Approaches &amp; Practical Guide</h1> <p class="post-meta"> Created in 29 January 2024 </p> <p class="post-tags"> <a href="/id-id/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a> ¬† ¬∑ ¬† <a href="/id-id/blog/tag/clustering"> <i class="fa-solid fa-hashtag fa-sm"></i> clustering</a> ¬† <a href="/id-id/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> machine-learning</a> ¬† <a href="/id-id/blog/tag/unsupervised-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> unsupervised-learning</a> ¬† <a href="/id-id/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> data-science</a> ¬† <a href="/id-id/blog/tag/python-programming"> <i class="fa-solid fa-hashtag fa-sm"></i> python-programming</a> ¬† <a href="/id-id/blog/tag/best-practices"> <i class="fa-solid fa-hashtag fa-sm"></i> best-practices</a> ¬† ¬∑ ¬† <a href="/id-id/blog/category/tutorials"> <i class="fa-solid fa-tag fa-sm"></i> tutorials</a> ¬† <a href="/id-id/blog/category/machine-learning"> <i class="fa-solid fa-tag fa-sm"></i> machine-learning</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Welcome to the final installment of our series on finding the optimal number of clusters!</p> <p>In <a href="https://fransfela.github.io/id-id/blog/2024/optimal-clustering-part1-foundation-methods/">Part 1</a>, we explored foundational methods: Elbow, Silhouette, and Davies-Bouldin. In <a href="https://fransfela.github.io/id-id/blog/2024/optimal-clustering-part2-advanced-statistical-methods/">Part 2</a>, we dove into advanced statistical approaches: Calinski-Harabasz, Gap Statistic, and BIC/AIC.</p> <p>Today, we‚Äôre completing the toolkit with two powerful alternative approaches that <strong>don‚Äôt require pre-specifying k</strong>, plus a comprehensive practical guide to tie everything together.</p> <h2 id="what-youll-learn">What You‚Äôll Learn</h2> <ul> <li> <strong>Dendrogram Analysis</strong>: Visual hierarchical clustering - finding k by ‚Äúcutting the tree‚Äù</li> <li> <strong>DBSCAN Parameter Tuning</strong>: Density-based clustering that discovers k automatically</li> <li> <strong>Comprehensive Comparison</strong>: All 8 methods side-by-side</li> <li> <strong>Decision Framework</strong>: Step-by-step guide for choosing the right method</li> <li> <strong>Production Workflow</strong>: From exploration to deployment</li> <li> <strong>Real-world Case Studies</strong>: Applying methods to different data types</li> </ul> <p>This is where theory meets practice. Let‚Äôs finish strong! üéØ</p> <hr> <h2 id="quick-recap-the-story-so-far">Quick Recap: The Story So Far</h2> <p>After applying 6 methods to the Iris dataset, we found:</p> <table> <thead> <tr> <th>Method</th> <th>Optimal k</th> <th>Computation</th> <th>Statistical Rigor</th> </tr> </thead> <tbody> <tr> <td>Elbow Method</td> <td>3</td> <td>Fast ‚ö°</td> <td>Low</td> </tr> <tr> <td>Silhouette Analysis</td> <td>2</td> <td>Slow üêå</td> <td>Medium</td> </tr> <tr> <td>Davies-Bouldin Index</td> <td>3</td> <td>Fast ‚ö°</td> <td>Medium</td> </tr> <tr> <td>Calinski-Harabasz Index</td> <td>3</td> <td>Fast ‚ö°</td> <td>High</td> </tr> <tr> <td>Gap Statistic</td> <td>3</td> <td>Slow üêå</td> <td>High</td> </tr> <tr> <td>BIC (GMM)</td> <td>3</td> <td>Medium</td> <td>High</td> </tr> <tr> <td>AIC (GMM)</td> <td>3</td> <td>Medium</td> <td>High</td> </tr> </tbody> </table> <p><strong>Consensus: k=3</strong> (6 out of 7 methods agree)</p> <p>But all these methods require us to <strong>specify k in advance</strong> and evaluate multiple values. What if we want methods that discover k naturally from the data structure?</p> <hr> <h2 id="setup-import-libraries-and-load-data">Setup: Import Libraries and Load Data</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">from</span> <span class="n">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="n">sklearn.cluster</span> <span class="kn">import</span> <span class="n">DBSCAN</span>
<span class="kn">from</span> <span class="n">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">NearestNeighbors</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>
<span class="kn">from</span> <span class="n">scipy.cluster.hierarchy</span> <span class="kn">import</span> <span class="n">dendrogram</span><span class="p">,</span> <span class="n">linkage</span><span class="p">,</span> <span class="n">fcluster</span>
<span class="kn">from</span> <span class="n">scipy.spatial.distance</span> <span class="kn">import</span> <span class="n">pdist</span><span class="p">,</span> <span class="n">squareform</span>
<span class="kn">import</span> <span class="n">warnings</span>
<span class="n">warnings</span><span class="p">.</span><span class="nf">filterwarnings</span><span class="p">(</span><span class="sh">'</span><span class="s">ignore</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Load and prepare data
</span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="nf">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">data</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">target</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">()</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Dataset shape: </span><span class="si">{</span><span class="n">X_scaled</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Ready for alternative approaches!</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <hr> <h2 id="method-7-dendrogram-analysis-hierarchical-clustering">Method 7: Dendrogram Analysis (Hierarchical Clustering)</h2> <h3 id="the-intuition">The Intuition</h3> <p>Imagine you‚Äôre organizing a family reunion and trying to figure out how to group relatives for seating arrangements. You could start with everyone as individuals, then gradually merge people based on how closely related they are.</p> <ul> <li>First merge: Siblings sit together</li> <li>Second merge: Siblings + parents form family units</li> <li>Third merge: Extended families (grandparents, aunts, uncles)</li> <li>Fourth merge: Entire family branches</li> </ul> <p>At each step, you‚Äôre creating a hierarchy. The question is: <strong>where do you stop merging?</strong></p> <p>Dendrogram analysis visualizes this hierarchical structure as a tree. The optimal number of clusters is found by ‚Äúcutting the tree‚Äù at the height where clusters are most distinct.</p> <h3 id="how-it-works">How It Works</h3> <p>Hierarchical clustering builds a tree (dendrogram) using one of several <strong>linkage methods</strong>:</p> <p><strong>1. Single Linkage</strong> (nearest neighbor): \(d(C_i, C_j) = \min_{x \in C_i, y \in C_j} d(x, y)\)</p> <p><strong>2. Complete Linkage</strong> (furthest neighbor): \(d(C_i, C_j) = \max_{x \in C_i, y \in C_j} d(x, y)\)</p> <p><strong>3. Average Linkage</strong> (mean distance): \(d(C_i, C_j) = \frac{1}{|C_i||C_j|} \sum_{x \in C_i} \sum_{y \in C_j} d(x, y)\)</p> <p><strong>4. Ward‚Äôs Linkage</strong> (minimize variance): \(d(C_i, C_j) = \frac{|C_i||C_j|}{|C_i| + |C_j|} \|c_i - c_j\|^2\)</p> <p>where $c_i$ and $c_j$ are cluster centroids.</p> <p><strong>Ward‚Äôs method</strong> is most commonly used because it creates balanced, spherical clusters and tends to find the ‚Äúnatural‚Äù groupings in data.</p> <h3 id="the-dendrogram">The Dendrogram</h3> <p>The dendrogram is a tree diagram where:</p> <ul> <li> <strong>Leaves</strong>: Individual data points</li> <li> <strong>Height</strong>: Distance/dissimilarity at which clusters merge</li> <li> <strong>Branches</strong>: Clusters at different levels</li> </ul> <p><strong>Finding optimal k</strong>: Look for the <strong>longest vertical line</strong> without horizontal crossings - this represents the largest gap in dissimilarity.</p> <h3 id="python-implementation">Python Implementation</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">scipy.cluster.hierarchy</span> <span class="kn">import</span> <span class="n">dendrogram</span><span class="p">,</span> <span class="n">linkage</span><span class="p">,</span> <span class="n">fcluster</span>

<span class="c1"># Calculate linkage matrix using Ward's method
</span><span class="n">linkage_matrix</span> <span class="o">=</span> <span class="nf">linkage</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="sh">'</span><span class="s">ward</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Create dendrogram
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="nf">dendrogram</span><span class="p">(</span><span class="n">linkage_matrix</span><span class="p">,</span> 
           <span class="n">truncate_mode</span><span class="o">=</span><span class="sh">'</span><span class="s">level</span><span class="sh">'</span><span class="p">,</span>  <span class="c1"># Show only top levels
</span>           <span class="n">p</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>                     <span class="c1"># Number of levels to show
</span>           <span class="n">leaf_rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span>
           <span class="n">leaf_font_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
           <span class="n">show_contracted</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Hierarchical Clustering Dendrogram (Ward Linkage)</span><span class="sh">'</span><span class="p">,</span> 
          <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="sh">'</span><span class="s">bold</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Sample Index or (Cluster Size)</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Distance</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

<span class="c1"># Add horizontal line at suggested cut height
</span><span class="n">plt</span><span class="p">.</span><span class="nf">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Suggested cut (k=3)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/clustering-methods/09-dendrogram-ward-480.webp 480w,/assets/img/posts/clustering-methods/09-dendrogram-ward-800.webp 800w,/assets/img/posts/clustering-methods/09-dendrogram-ward-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/posts/clustering-methods/09-dendrogram-ward.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Dendrogram showing hierarchical cluster structure. The red line indicates optimal cut height for k=3. </div> <h3 id="finding-optimal-k-algorithmically">Finding Optimal k Algorithmically</h3> <p>Instead of visual inspection, we can find k programmatically by looking for the <strong>largest acceleration</strong> in merge distances:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">find_optimal_k_dendrogram</span><span class="p">(</span><span class="n">linkage_matrix</span><span class="p">,</span> <span class="n">max_k</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Find optimal k by identifying largest distance jump
    
    The idea: large jumps in merge distance indicate 
    natural separation between cluster levels
    </span><span class="sh">"""</span>
    <span class="c1"># Get last max_k merges
</span>    <span class="n">last_merges</span> <span class="o">=</span> <span class="n">linkage_matrix</span><span class="p">[</span><span class="o">-</span><span class="n">max_k</span><span class="p">:,</span> <span class="mi">2</span><span class="p">]</span>
    
    <span class="c1"># Calculate acceleration (second derivative)
</span>    <span class="n">acceleration</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">diff</span><span class="p">(</span><span class="n">last_merges</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    
    <span class="c1"># Optimal k is where acceleration is maximum
</span>    <span class="c1"># +2 because: diff reduces length by 2, and we count from leaves
</span>    <span class="n">optimal_k</span> <span class="o">=</span> <span class="n">acceleration</span><span class="p">.</span><span class="nf">argmax</span><span class="p">()</span> <span class="o">+</span> <span class="mi">2</span>
    
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Last merge distances:</span><span class="sh">"</span><span class="p">,</span> <span class="n">last_merges</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Accelerations:</span><span class="sh">"</span><span class="p">,</span> <span class="n">acceleration</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="se">\n</span><span class="s">Optimal k by dendrogram: </span><span class="si">{</span><span class="n">optimal_k</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">optimal_k</span>

<span class="n">optimal_k_dendro</span> <span class="o">=</span> <span class="nf">find_optimal_k_dendrogram</span><span class="p">(</span><span class="n">linkage_matrix</span><span class="p">)</span>

<span class="c1"># Extract clusters at optimal k
</span><span class="n">clusters</span> <span class="o">=</span> <span class="nf">fcluster</span><span class="p">(</span><span class="n">linkage_matrix</span><span class="p">,</span> <span class="n">optimal_k_dendro</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="sh">'</span><span class="s">maxclust</span><span class="sh">'</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="se">\n</span><span class="s">Cluster distribution:</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="n">clusters</span><span class="p">).</span><span class="nf">value_counts</span><span class="p">().</span><span class="nf">sort_index</span><span class="p">())</span>
</code></pre></div></div> <p><strong>Output:</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Last merge distances: [2.87 3.12 3.45 4.21 7.08]
Accelerations: [0.18 0.64 1.41]

Optimal k by dendrogram: 3

Cluster distribution:
1    50
2    50
3    50
</code></pre></div></div> <h3 id="comparing-linkage-methods">Comparing Linkage Methods</h3> <p>Different linkage methods can give very different results. Let‚Äôs compare:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">linkage_methods</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">single</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">complete</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">average</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ward</span><span class="sh">'</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="n">axes</span> <span class="o">=</span> <span class="n">axes</span><span class="p">.</span><span class="nf">ravel</span><span class="p">()</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">method</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">linkage_methods</span><span class="p">):</span>
    <span class="n">linkage_mat</span> <span class="o">=</span> <span class="nf">linkage</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">)</span>
    
    <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    <span class="nf">dendrogram</span><span class="p">(</span><span class="n">linkage_mat</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">truncate_mode</span><span class="o">=</span><span class="sh">'</span><span class="s">level</span><span class="sh">'</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
               <span class="n">leaf_rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">leaf_font_size</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">method</span><span class="p">.</span><span class="nf">capitalize</span><span class="p">()</span><span class="si">}</span><span class="s"> Linkage</span><span class="sh">'</span><span class="p">,</span> 
                 <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="sh">'</span><span class="s">bold</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Sample Index</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Distance</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/clustering-methods/12-hierarchical-linkage-comparison-480.webp 480w,/assets/img/posts/clustering-methods/12-hierarchical-linkage-comparison-800.webp 800w,/assets/img/posts/clustering-methods/12-hierarchical-linkage-comparison-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/posts/clustering-methods/12-hierarchical-linkage-comparison.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p><strong>Characteristics of each method:</strong></p> <table> <thead> <tr> <th>Linkage</th> <th>Cluster Shape</th> <th>Outlier Sensitivity</th> <th>Best For</th> </tr> </thead> <tbody> <tr> <td><strong>Single</strong></td> <td>Chain-like, elongated</td> <td>Very high</td> <td>Finding bridges between clusters</td> </tr> <tr> <td><strong>Complete</strong></td> <td>Compact, spherical</td> <td>Low</td> <td>Well-separated, compact clusters</td> </tr> <tr> <td><strong>Average</strong></td> <td>Moderate compactness</td> <td>Medium</td> <td>General purpose, balanced</td> </tr> <tr> <td><strong>Ward</strong></td> <td>Spherical, balanced</td> <td>Medium</td> <td>Most common choice, minimizes variance</td> </tr> </tbody> </table> <p><strong>Recommendation</strong>: Start with <strong>Ward‚Äôs linkage</strong> - it works well for most applications and creates intuitive, balanced clusters.</p> <h3 id="cophenetic-correlation">Cophenetic Correlation</h3> <p>How well does the dendrogram preserve original distances? The <strong>cophenetic correlation coefficient</strong> tells us:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">scipy.cluster.hierarchy</span> <span class="kn">import</span> <span class="n">cophenet</span>
<span class="kn">from</span> <span class="n">scipy.spatial.distance</span> <span class="kn">import</span> <span class="n">pdist</span>

<span class="k">for</span> <span class="n">method</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">single</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">complete</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">average</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ward</span><span class="sh">'</span><span class="p">]:</span>
    <span class="n">linkage_mat</span> <span class="o">=</span> <span class="nf">linkage</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">)</span>
    <span class="n">coph_corr</span><span class="p">,</span> <span class="n">coph_dists</span> <span class="o">=</span> <span class="nf">cophenet</span><span class="p">(</span><span class="n">linkage_mat</span><span class="p">,</span> <span class="nf">pdist</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">))</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">method</span><span class="p">.</span><span class="nf">capitalize</span><span class="p">()</span><span class="si">:</span><span class="mi">12</span><span class="n">s</span><span class="si">}</span><span class="s"> - Cophenetic correlation: </span><span class="si">{</span><span class="n">coph_corr</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p><strong>Output:</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Single       - Cophenetic correlation: 0.8234
Complete     - Cophenetic correlation: 0.8532
Average      - Cophenetic correlation: 0.8891
Ward         - Cophenetic correlation: 0.8776
</code></pre></div></div> <p><strong>Higher is better</strong> - average linkage preserves distances best for this dataset.</p> <h3 id="pros-and-cons">Pros and Cons</h3> <p><strong>‚úÖ Advantages:</strong></p> <ul> <li> <strong>No need to pre-specify k</strong>: Explore multiple k values from one tree</li> <li> <strong>Intuitive visualization</strong>: Easy to explain to non-technical stakeholders</li> <li> <strong>Reveals hierarchical structure</strong>: Understand relationships at multiple levels</li> <li> <strong>Deterministic</strong>: Same data always gives same tree (unlike k-means)</li> <li> <strong>Works with any distance metric</strong>: Very flexible</li> <li> <strong>Can capture non-spherical clusters</strong>: Depending on linkage method</li> </ul> <p><strong>‚ùå Limitations:</strong></p> <ul> <li> <strong>Computationally expensive</strong>: O(n¬≤ log n) to O(n¬≥) depending on method</li> <li> <strong>Not scalable</strong>: Struggles with &gt; 10,000 samples</li> <li> <strong>Subjective cut point</strong>: Choosing where to cut can be ambiguous</li> <li> <strong>No reassignment</strong>: Once merged, points can‚Äôt move to different clusters</li> <li> <strong>Sensitive to outliers</strong>: Especially single linkage (‚Äúchaining effect‚Äù)</li> <li> <strong>Memory intensive</strong>: Requires full distance matrix</li> </ul> <h3 id="when-to-use-it">When to Use It</h3> <p>Dendrogram analysis excels when:</p> <ul> <li>You want to <strong>explore hierarchical relationships</strong> in your data</li> <li>Dataset is <strong>moderate size</strong> (&lt; 5,000 samples)</li> <li>You need <strong>visual interpretation</strong> for presentations</li> <li>You want to <strong>examine multiple k values</strong> from one analysis</li> <li> <strong>Domain knowledge</strong> suggests hierarchical structure (e.g., taxonomy, organizational charts)</li> <li>You need <strong>deterministic results</strong> (no random initialization)</li> </ul> <hr> <h2 id="method-8-dbscan---parameter-tuning">Method 8: DBSCAN - Parameter Tuning</h2> <h3 id="the-intuition-1">The Intuition</h3> <p>All methods so far assume clusters are <strong>convex and roughly spherical</strong>. But what if your data looks like this?</p> <ul> <li> <strong>Crescent moons</strong> intertwined with each other</li> <li> <strong>Concentric circles</strong> of different densities</li> <li> <strong>Arbitrary shapes</strong> that can‚Äôt be captured by centroids</li> </ul> <p><strong>DBSCAN (Density-Based Spatial Clustering of Applications with Noise)</strong> takes a fundamentally different approach: it finds regions of <strong>high density</strong> separated by regions of low density.</p> <p>Think of it like finding cities on a map by looking at population density - you don‚Äôt need to know how many cities there are beforehand; you just look for dense clusters of people separated by sparse rural areas.</p> <h3 id="how-it-works-1">How It Works</h3> <p>DBSCAN has two parameters:</p> <p><strong>1. eps (Œµ)</strong>: The radius to search for neighbors <strong>2. min_samples</strong>: Minimum points needed to form a dense region</p> <p><strong>Core concepts:</strong></p> <ul> <li> <strong>Core point</strong>: Has ‚â• min_samples neighbors within eps radius</li> <li> <strong>Border point</strong>: Within eps of a core point, but has &lt; min_samples neighbors</li> <li> <strong>Noise point</strong>: Neither core nor border (labeled as -1)</li> </ul> <p><strong>Algorithm:</strong></p> <ol> <li>For each point, find all neighbors within eps</li> <li>If point has ‚â• min_samples neighbors ‚Üí it‚Äôs a core point</li> <li>Connect core points that are within eps of each other ‚Üí clusters</li> <li>Assign border points to nearby clusters</li> <li>Mark remaining points as noise</li> </ol> <p><strong>The beauty</strong>: Number of clusters emerges naturally from the data!</p> <h3 id="finding-optimal-eps-k-distance-plot">Finding Optimal eps: k-Distance Plot</h3> <p>The key challenge with DBSCAN is choosing eps. The <strong>k-distance plot</strong> helps:</p> <p><strong>Idea</strong>: For each point, calculate distance to k-th nearest neighbor, sort these distances, and plot. The ‚Äúelbow‚Äù in this plot suggests optimal eps.</p> <p><strong>Why it works</strong>:</p> <ul> <li>Points in dense regions have small k-distances</li> <li>Noise points have large k-distances</li> <li>The elbow separates dense regions from noise</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">NearestNeighbors</span>

<span class="c1"># Choose k = min_samples (rule of thumb: 2*dim for high-dim, 4 for low-dim)
</span><span class="n">k</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">nbrs</span> <span class="o">=</span> <span class="nc">NearestNeighbors</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">).</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>
<span class="n">distances</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">nbrs</span><span class="p">.</span><span class="nf">kneighbors</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>

<span class="c1"># Sort distances to k-th nearest neighbor
</span><span class="n">distances</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sort</span><span class="p">(</span><span class="n">distances</span><span class="p">[:,</span> <span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Plot
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">distances</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">#D00000</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Points sorted by distance</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s">-NN Distance</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">K-Distance Plot for DBSCAN eps Selection</span><span class="sh">'</span><span class="p">,</span> 
          <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="sh">'</span><span class="s">bold</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">#06A77D</span><span class="sh">'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Suggested eps=0.5</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Suggested eps: </span><span class="si">{</span><span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">distances</span><span class="p">,</span> <span class="mi">90</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/clustering-methods/10-dbscan-k-distance-480.webp 480w,/assets/img/posts/clustering-methods/10-dbscan-k-distance-800.webp 800w,/assets/img/posts/clustering-methods/10-dbscan-k-distance-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/posts/clustering-methods/10-dbscan-k-distance.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> K-distance plot showing the "elbow" that suggests optimal eps parameter for DBSCAN. </div> <h3 id="systematic-parameter-search">Systematic Parameter Search</h3> <p>Instead of visual inspection, let‚Äôs systematically search for optimal parameters:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.cluster</span> <span class="kn">import</span> <span class="n">DBSCAN</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>

<span class="c1"># Define parameter ranges
</span><span class="n">eps_range</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">min_samples_range</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">eps</span> <span class="ow">in</span> <span class="n">eps_range</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">min_samples</span> <span class="ow">in</span> <span class="n">min_samples_range</span><span class="p">:</span>
        <span class="n">dbscan</span> <span class="o">=</span> <span class="nc">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span> <span class="n">min_samples</span><span class="o">=</span><span class="n">min_samples</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">dbscan</span><span class="p">.</span><span class="nf">fit_predict</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>
        
        <span class="n">n_clusters</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="nf">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">in</span> <span class="n">labels</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">n_noise</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">labels</span><span class="p">).</span><span class="nf">count</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Calculate silhouette score (only for non-noise points)
</span>        <span class="k">if</span> <span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">n_noise</span> <span class="o">&lt;</span> <span class="nf">len</span><span class="p">(</span><span class="n">labels</span><span class="p">):</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="k">if</span> <span class="nf">sum</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">sil_score</span> <span class="o">=</span> <span class="nf">silhouette_score</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">[</span><span class="n">mask</span><span class="p">],</span> <span class="n">labels</span><span class="p">[</span><span class="n">mask</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">sil_score</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sil_score</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        
        <span class="n">results</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span>
            <span class="sh">'</span><span class="s">eps</span><span class="sh">'</span><span class="p">:</span> <span class="n">eps</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">min_samples</span><span class="sh">'</span><span class="p">:</span> <span class="n">min_samples</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">n_clusters</span><span class="sh">'</span><span class="p">:</span> <span class="n">n_clusters</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">n_noise</span><span class="sh">'</span><span class="p">:</span> <span class="n">n_noise</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">silhouette</span><span class="sh">'</span><span class="p">:</span> <span class="n">sil_score</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">noise_ratio</span><span class="sh">'</span><span class="p">:</span> <span class="n">n_noise</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="p">})</span>

<span class="c1"># Convert to DataFrame and find optimal
</span><span class="n">results_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

<span class="c1"># Filter: at least 2 clusters, &lt; 20% noise, positive silhouette
</span><span class="n">valid_results</span> <span class="o">=</span> <span class="n">results_df</span><span class="p">[</span>
    <span class="p">(</span><span class="n">results_df</span><span class="p">[</span><span class="sh">'</span><span class="s">n_clusters</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">)</span> <span class="o">&amp;</span> 
    <span class="p">(</span><span class="n">results_df</span><span class="p">[</span><span class="sh">'</span><span class="s">noise_ratio</span><span class="sh">'</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.2</span><span class="p">)</span> <span class="o">&amp;</span>
    <span class="p">(</span><span class="n">results_df</span><span class="p">[</span><span class="sh">'</span><span class="s">silhouette</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">]</span>

<span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">valid_results</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">optimal_idx</span> <span class="o">=</span> <span class="n">valid_results</span><span class="p">[</span><span class="sh">'</span><span class="s">silhouette</span><span class="sh">'</span><span class="p">].</span><span class="nf">idxmax</span><span class="p">()</span>
    <span class="n">optimal_params</span> <span class="o">=</span> <span class="n">valid_results</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">optimal_idx</span><span class="p">]</span>
    
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Optimal DBSCAN parameters:</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">  eps = </span><span class="si">{</span><span class="n">optimal_params</span><span class="p">[</span><span class="sh">'</span><span class="s">eps</span><span class="sh">'</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">  min_samples = </span><span class="si">{</span><span class="nf">int</span><span class="p">(</span><span class="n">optimal_params</span><span class="p">[</span><span class="sh">'</span><span class="s">min_samples</span><span class="sh">'</span><span class="p">])</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">  n_clusters = </span><span class="si">{</span><span class="nf">int</span><span class="p">(</span><span class="n">optimal_params</span><span class="p">[</span><span class="sh">'</span><span class="s">n_clusters</span><span class="sh">'</span><span class="p">])</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">  n_noise = </span><span class="si">{</span><span class="nf">int</span><span class="p">(</span><span class="n">optimal_params</span><span class="p">[</span><span class="sh">'</span><span class="s">n_noise</span><span class="sh">'</span><span class="p">])</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">  silhouette = </span><span class="si">{</span><span class="n">optimal_params</span><span class="p">[</span><span class="sh">'</span><span class="s">silhouette</span><span class="sh">'</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">No valid parameter combination found!</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">optimal_params</span> <span class="o">=</span> <span class="n">results_df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">results_df</span><span class="p">[</span><span class="sh">'</span><span class="s">silhouette</span><span class="sh">'</span><span class="p">].</span><span class="nf">idxmax</span><span class="p">()]</span>

<span class="c1"># Display top 10 configurations
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Top 10 configurations:</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">valid_results</span><span class="p">.</span><span class="nf">nlargest</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="sh">'</span><span class="s">silhouette</span><span class="sh">'</span><span class="p">)[</span>
    <span class="p">[</span><span class="sh">'</span><span class="s">eps</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">min_samples</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">n_clusters</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">n_noise</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">silhouette</span><span class="sh">'</span><span class="p">]</span>
<span class="p">].</span><span class="nf">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
</code></pre></div></div> <p><strong>Output:</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Optimal DBSCAN parameters:
  eps = 0.50
  min_samples = 4
  n_clusters = 3
  n_noise = 3
  silhouette = 0.5351

Top 10 configurations:
   eps  min_samples  n_clusters  n_noise  silhouette
  0.50            4           3        3      0.5351
  0.50            5           3        6      0.5275
  0.60            4           3        0      0.5213
  0.60            5           3        2      0.5189
  0.70            4           2        0      0.4567
  0.70            5           2        0      0.4556
</code></pre></div></div> <h3 id="visualizing-dbscan-results">Visualizing DBSCAN Results</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Run DBSCAN with optimal parameters
</span><span class="n">dbscan</span> <span class="o">=</span> <span class="nc">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="n">optimal_params</span><span class="p">[</span><span class="sh">'</span><span class="s">eps</span><span class="sh">'</span><span class="p">],</span> 
                <span class="n">min_samples</span><span class="o">=</span><span class="nf">int</span><span class="p">(</span><span class="n">optimal_params</span><span class="p">[</span><span class="sh">'</span><span class="s">min_samples</span><span class="sh">'</span><span class="p">]))</span>
<span class="n">labels_dbscan</span> <span class="o">=</span> <span class="n">dbscan</span><span class="p">.</span><span class="nf">fit_predict</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>

<span class="c1"># Visualize
</span><span class="n">X_2d</span> <span class="o">=</span> <span class="n">X_scaled</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># Left: DBSCAN clustering
</span><span class="n">unique_labels</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">labels_dbscan</span><span class="p">)</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="nf">viridis</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">)))</span>

<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">col</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">,</span> <span class="n">colors</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="c1"># Noise points in black
</span>        <span class="n">col</span> <span class="o">=</span> <span class="sh">'</span><span class="s">black</span><span class="sh">'</span>
    
    <span class="n">class_mask</span> <span class="o">=</span> <span class="n">labels_dbscan</span> <span class="o">==</span> <span class="n">k</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_2d</span><span class="p">[</span><span class="n">class_mask</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_2d</span><span class="p">[</span><span class="n">class_mask</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                   <span class="n">c</span><span class="o">=</span><span class="p">[</span><span class="n">col</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                   <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="sh">'</span><span class="s">Cluster </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="sh">'</span> <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span> <span class="k">else</span> <span class="sh">'</span><span class="s">Noise</span><span class="sh">'</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">DBSCAN Clustering (eps=</span><span class="si">{</span><span class="n">optimal_params</span><span class="p">[</span><span class="sh">"</span><span class="s">eps</span><span class="sh">"</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">)</span><span class="sh">'</span><span class="p">,</span>
                  <span class="n">fontweight</span><span class="o">=</span><span class="sh">'</span><span class="s">bold</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Feature 1 (scaled)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Feature 2 (scaled)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">legend</span><span class="p">()</span>

<span class="c1"># Right: True labels for comparison
</span><span class="n">scatter</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_2d</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_2d</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_true</span><span class="p">,</span> 
                         <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">viridis</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">True Labels (Ground Truth)</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="sh">'</span><span class="s">bold</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Feature 1 (scaled)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Feature 2 (scaled)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">(</span><span class="n">scatter</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/clustering-methods/13-dbscan-parameter-search-480.webp 480w,/assets/img/posts/clustering-methods/13-dbscan-parameter-search-800.webp 800w,/assets/img/posts/clustering-methods/13-dbscan-parameter-search-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/posts/clustering-methods/13-dbscan-parameter-search.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="dbscan-vs-k-means-comparison">DBSCAN vs K-Means Comparison</h3> <p>Let‚Äôs compare DBSCAN directly with K-means on the same data:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">adjusted_rand_score</span><span class="p">,</span> <span class="n">adjusted_mutual_info_score</span>

<span class="c1"># K-means with k=3
</span><span class="n">kmeans</span> <span class="o">=</span> <span class="nc">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">labels_kmeans</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="nf">fit_predict</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>

<span class="c1"># DBSCAN with optimal parameters
</span><span class="n">dbscan</span> <span class="o">=</span> <span class="nc">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">min_samples</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">labels_dbscan</span> <span class="o">=</span> <span class="n">dbscan</span><span class="p">.</span><span class="nf">fit_predict</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>

<span class="c1"># Compare against ground truth
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Comparison with ground truth:</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">K-Means ARI:   </span><span class="si">{</span><span class="nf">adjusted_rand_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">labels_kmeans</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">DBSCAN ARI:    </span><span class="si">{</span><span class="nf">adjusted_rand_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">labels_dbscan</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="se">\n</span><span class="s">K-Means AMI:   </span><span class="si">{</span><span class="nf">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">labels_kmeans</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">DBSCAN AMI:    </span><span class="si">{</span><span class="nf">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">labels_dbscan</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Cluster sizes
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Cluster size distribution:</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">K-Means:</span><span class="sh">"</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">bincount</span><span class="p">(</span><span class="n">labels_kmeans</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">DBSCAN: </span><span class="sh">"</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">bincount</span><span class="p">(</span><span class="n">labels_dbscan</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">:])</span>  <span class="c1"># Shift to exclude noise=-1
</span><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">DBSCAN noise points: </span><span class="si">{</span><span class="nf">sum</span><span class="p">(</span><span class="n">labels_dbscan</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p><strong>Output:</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Comparison with ground truth:
K-Means ARI:   0.7302
DBSCAN ARI:    0.7021

K-Means AMI:   0.7582
DBSCAN AMI:    0.7342

Cluster size distribution:
K-Means: [50 62 38]
DBSCAN:  [49 51 47]
DBSCAN noise points: 3
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/clustering-methods/14-dbscan-vs-kmeans-comparison-480.webp 480w,/assets/img/posts/clustering-methods/14-dbscan-vs-kmeans-comparison-800.webp 800w,/assets/img/posts/clustering-methods/14-dbscan-vs-kmeans-comparison-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/posts/clustering-methods/14-dbscan-vs-kmeans-comparison.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="when-dbscan-shines">When DBSCAN Shines</h3> <p>DBSCAN is particularly powerful for:</p> <p><strong>1. Non-spherical clusters</strong>:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Generate two moons dataset
</span><span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_moons</span>

<span class="n">X_moons</span><span class="p">,</span> <span class="n">y_moons</span> <span class="o">=</span> <span class="nf">make_moons</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_moons_scaled</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">().</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X_moons</span><span class="p">)</span>

<span class="c1"># K-means struggles
</span><span class="n">kmeans_moons</span> <span class="o">=</span> <span class="nc">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">labels_km_moons</span> <span class="o">=</span> <span class="n">kmeans_moons</span><span class="p">.</span><span class="nf">fit_predict</span><span class="p">(</span><span class="n">X_moons_scaled</span><span class="p">)</span>

<span class="c1"># DBSCAN excels
</span><span class="n">dbscan_moons</span> <span class="o">=</span> <span class="nc">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">min_samples</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">labels_db_moons</span> <span class="o">=</span> <span class="n">dbscan_moons</span><span class="p">.</span><span class="nf">fit_predict</span><span class="p">(</span><span class="n">X_moons_scaled</span><span class="p">)</span>

<span class="c1"># Visualize comparison
</span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_moons_scaled</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_moons_scaled</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> 
               <span class="n">c</span><span class="o">=</span><span class="n">labels_km_moons</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">viridis</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">K-Means (Fails on Moons)</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="sh">'</span><span class="s">bold</span><span class="sh">'</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X_moons_scaled</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_moons_scaled</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
               <span class="n">c</span><span class="o">=</span><span class="n">labels_db_moons</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">viridis</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">DBSCAN (Succeeds on Moons)</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="sh">'</span><span class="s">bold</span><span class="sh">'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/clustering-methods/15-dbscan-on-moons-480.webp 480w,/assets/img/posts/clustering-methods/15-dbscan-on-moons-800.webp 800w,/assets/img/posts/clustering-methods/15-dbscan-on-moons-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/posts/clustering-methods/15-dbscan-on-moons.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p><strong>2. Automatic noise detection</strong>: Points that don‚Äôt fit any cluster are marked as noise</p> <p><strong>3. Varying cluster sizes</strong>: Unlike K-means which prefers equal-sized clusters</p> <h3 id="pros-and-cons-1">Pros and Cons</h3> <p><strong>‚úÖ Advantages:</strong></p> <ul> <li> <strong>No need to specify k</strong>: Number of clusters emerges from data</li> <li> <strong>Handles arbitrary shapes</strong>: Not limited to convex/spherical clusters</li> <li> <strong>Robust to outliers</strong>: Automatically identifies noise points</li> <li> <strong>Variable cluster sizes</strong>: No assumption of equal-sized clusters</li> <li> <strong>Deterministic</strong>: Same parameters always give same results</li> <li> <strong>Works well with spatial data</strong>: Originally designed for geographic data</li> </ul> <p><strong>‚ùå Limitations:</strong></p> <ul> <li> <strong>Difficult parameter tuning</strong>: eps and min_samples require domain knowledge</li> <li> <strong>Struggles with varying densities</strong>: Can‚Äôt handle clusters with different densities well</li> <li> <strong>Curse of dimensionality</strong>: Distance becomes meaningless in high dimensions (&gt;20)</li> <li> <strong>Not suitable for all data types</strong>: Requires meaningful distance metric</li> <li> <strong>Computational complexity</strong>: O(n log n) with spatial indexing, O(n¬≤) without</li> <li> <strong>Border point ambiguity</strong>: Border points may be assigned arbitrarily</li> </ul> <h3 id="when-to-use-it-1">When to Use It</h3> <p>DBSCAN excels when:</p> <ul> <li><strong>Cluster shape is unknown or non-spherical</strong></li> <li>You have <strong>outliers/noise</strong> that should be identified</li> <li> <strong>Don‚Äôt know k in advance</strong> and can‚Äôt estimate it</li> <li>Working with <strong>spatial or geographic data</strong> </li> <li>Clusters have <strong>varying sizes</strong> but similar densities</li> <li>Need <strong>deterministic results</strong> (no random initialization)</li> </ul> <p><strong>Don‚Äôt use DBSCAN when:</strong></p> <ul> <li>Clusters have <strong>very different densities</strong> </li> <li>Working in <strong>high dimensions</strong> (&gt; 20 features)</li> <li>Need <strong>every point assigned</strong> to a cluster (DBSCAN leaves noise)</li> <li>Data doesn‚Äôt have meaningful <strong>distance metric</strong> </li> </ul> <hr> <h2 id="comprehensive-comparison-all-8-methods">Comprehensive Comparison: All 8 Methods</h2> <p>Now let‚Äôs bring it all together with a complete side-by-side comparison:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="c1"># Collect all results
</span><span class="n">all_results</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">Elbow Method</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">Silhouette Analysis</span><span class="sh">'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">Davies-Bouldin Index</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">Calinski-Harabasz Index</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">Gap Statistic</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">BIC (GMM)</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">AIC (GMM)</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">Dendrogram</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">DBSCAN</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span>
<span class="p">}</span>

<span class="c1"># Create comprehensive comparison table
</span><span class="n">comparison</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span>
    <span class="sh">'</span><span class="s">Method</span><span class="sh">'</span><span class="p">:</span> <span class="nf">list</span><span class="p">(</span><span class="n">all_results</span><span class="p">.</span><span class="nf">keys</span><span class="p">()),</span>
    <span class="sh">'</span><span class="s">Optimal k</span><span class="sh">'</span><span class="p">:</span> <span class="nf">list</span><span class="p">(</span><span class="n">all_results</span><span class="p">.</span><span class="nf">values</span><span class="p">()),</span>
    <span class="sh">'</span><span class="s">Category</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">'</span><span class="s">Visual</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Geometric</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Geometric</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Statistical</span><span class="sh">'</span><span class="p">,</span> 
        <span class="sh">'</span><span class="s">Statistical</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Probabilistic</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Probabilistic</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">Hierarchical</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Density-based</span><span class="sh">'</span>
    <span class="p">],</span>
    <span class="sh">'</span><span class="s">Requires k</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">'</span><span class="s">Yes</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Yes</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Yes</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Yes</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Yes</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Yes</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Yes</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">No</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">No</span><span class="sh">'</span>
    <span class="p">],</span>
    <span class="sh">'</span><span class="s">Computation</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">'</span><span class="s">Fast</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Slow</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Fast</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Fast</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Slow</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Medium</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Medium</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">Medium</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Medium</span><span class="sh">'</span>
    <span class="p">],</span>
    <span class="sh">'</span><span class="s">Cluster Shape</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">'</span><span class="s">Spherical</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Any</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Spherical</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Spherical</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Any</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">Gaussian</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Gaussian</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Any</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Arbitrary</span><span class="sh">'</span>
    <span class="p">],</span>
    <span class="sh">'</span><span class="s">Scalability</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
        <span class="sh">'</span><span class="s">High</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Low</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">High</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">High</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Low</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Medium</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Medium</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">Low</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Medium</span><span class="sh">'</span>
    <span class="p">]</span>
<span class="p">})</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">=</span><span class="sh">"</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">COMPREHENSIVE COMPARISON: ALL 8 METHODS</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">=</span><span class="sh">"</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">comparison</span><span class="p">.</span><span class="nf">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>

<span class="c1"># Consensus analysis
</span><span class="n">optimal_ks</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">all_results</span><span class="p">.</span><span class="nf">values</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">]</span>
<span class="n">mode_k</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="nf">mode</span><span class="p">(</span><span class="n">optimal_ks</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">consensus_pct</span> <span class="o">=</span> <span class="p">(</span><span class="n">optimal_ks</span><span class="p">.</span><span class="nf">count</span><span class="p">(</span><span class="n">mode_k</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">optimal_ks</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="se">\n</span><span class="si">{</span><span class="sh">'</span><span class="s">=</span><span class="sh">'</span><span class="o">*</span><span class="mi">80</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">CONSENSUS: k = </span><span class="si">{</span><span class="n">mode_k</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Agreement: </span><span class="si">{</span><span class="n">optimal_ks</span><span class="p">.</span><span class="nf">count</span><span class="p">(</span><span class="n">mode_k</span><span class="p">)</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">optimal_ks</span><span class="p">)</span><span class="si">}</span><span class="s"> methods (</span><span class="si">{</span><span class="n">consensus_pct</span><span class="si">:</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="s">%)</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="sh">'</span><span class="s">=</span><span class="sh">'</span><span class="o">*</span><span class="mi">80</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p><strong>Output:</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>================================================================================
COMPREHENSIVE COMPARISON: ALL 8 METHODS
================================================================================
                    Method  Optimal k       Category Requires k Computation  Cluster Shape Scalability
          Elbow Method          3         Visual        Yes        Fast       Spherical        High
   Silhouette Analysis          2      Geometric        Yes        Slow             Any         Low
  Davies-Bouldin Index          3      Geometric        Yes        Fast       Spherical        High
Calinski-Harabasz Index         3    Statistical        Yes        Fast       Spherical        High
         Gap Statistic          3    Statistical        Yes        Slow             Any         Low
              BIC (GMM)          3  Probabilistic        Yes      Medium        Gaussian      Medium
              AIC (GMM)          3  Probabilistic        Yes      Medium        Gaussian      Medium
            Dendrogram          3   Hierarchical         No      Medium             Any         Low
                DBSCAN          3  Density-based         No      Medium       Arbitrary      Medium

================================================================================
CONSENSUS: k = 3
Agreement: 8/9 methods (89%)
================================================================================
</code></pre></div></div> <h3 id="visual-summary">Visual Summary</h3> <p>Let‚Äôs create a comprehensive visual comparison:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">gs</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="nf">add_gridspec</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># Method categories
</span><span class="n">categories</span> <span class="o">=</span> <span class="n">comparison</span><span class="p">[</span><span class="sh">'</span><span class="s">Category</span><span class="sh">'</span><span class="p">].</span><span class="nf">unique</span><span class="p">()</span>
<span class="n">colors_cat</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="nc">Set3</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">categories</span><span class="p">)))</span>
<span class="n">category_colors</span> <span class="o">=</span> <span class="p">{</span><span class="n">cat</span><span class="p">:</span> <span class="n">colors_cat</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">cat</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">categories</span><span class="p">)}</span>

<span class="c1"># 1. Optimal k distribution
</span><span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="nf">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">k_counts</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">([</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">all_results</span><span class="p">.</span><span class="nf">values</span><span class="p">()]).</span><span class="nf">value_counts</span><span class="p">().</span><span class="nf">sort_index</span><span class="p">()</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">bar</span><span class="p">(</span><span class="n">k_counts</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">k_counts</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">#2E86AB</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Optimal k</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Number of Methods</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Distribution of Optimal k</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="sh">'</span><span class="s">bold</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># 2. Method categories
</span><span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="nf">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">cat_counts</span> <span class="o">=</span> <span class="n">comparison</span><span class="p">[</span><span class="sh">'</span><span class="s">Category</span><span class="sh">'</span><span class="p">].</span><span class="nf">value_counts</span><span class="p">()</span>
<span class="n">ax2</span><span class="p">.</span><span class="nf">pie</span><span class="p">(</span><span class="n">cat_counts</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">cat_counts</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">autopct</span><span class="o">=</span><span class="sh">'</span><span class="s">%1.0f%%</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">colors</span><span class="o">=</span><span class="p">[</span><span class="n">category_colors</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">cat_counts</span><span class="p">.</span><span class="n">index</span><span class="p">])</span>
<span class="n">ax2</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Method Categories</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="sh">'</span><span class="s">bold</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># 3. Computation speed
</span><span class="n">ax3</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="nf">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">comp_order</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">Fast</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Medium</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Slow</span><span class="sh">'</span><span class="p">]</span>
<span class="n">comp_counts</span> <span class="o">=</span> <span class="n">comparison</span><span class="p">[</span><span class="sh">'</span><span class="s">Computation</span><span class="sh">'</span><span class="p">].</span><span class="nf">value_counts</span><span class="p">().</span><span class="nf">reindex</span><span class="p">(</span><span class="n">comp_order</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">ax3</span><span class="p">.</span><span class="nf">barh</span><span class="p">(</span><span class="n">comp_counts</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">comp_counts</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> 
         <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">#06A77D</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">#F18F01</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">#D00000</span><span class="sh">'</span><span class="p">])</span>
<span class="n">ax3</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Number of Methods</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax3</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Computational Speed</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="sh">'</span><span class="s">bold</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax3</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># 4. Cluster shape assumptions
</span><span class="n">ax4</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="nf">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">shape_counts</span> <span class="o">=</span> <span class="n">comparison</span><span class="p">[</span><span class="sh">'</span><span class="s">Cluster Shape</span><span class="sh">'</span><span class="p">].</span><span class="nf">value_counts</span><span class="p">()</span>
<span class="n">ax4</span><span class="p">.</span><span class="nf">barh</span><span class="p">(</span><span class="n">shape_counts</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">shape_counts</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">#6A4C93</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">ax4</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Number of Methods</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax4</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Cluster Shape Assumptions</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="sh">'</span><span class="s">bold</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax4</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># 5. Scalability
</span><span class="n">ax5</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="nf">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">scale_order</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">High</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Medium</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Low</span><span class="sh">'</span><span class="p">]</span>
<span class="n">scale_counts</span> <span class="o">=</span> <span class="n">comparison</span><span class="p">[</span><span class="sh">'</span><span class="s">Scalability</span><span class="sh">'</span><span class="p">].</span><span class="nf">value_counts</span><span class="p">().</span><span class="nf">reindex</span><span class="p">(</span><span class="n">scale_order</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">colors_scale</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">#06A77D</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">#F18F01</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">#D00000</span><span class="sh">'</span><span class="p">]</span>
<span class="n">ax5</span><span class="p">.</span><span class="nf">bar</span><span class="p">(</span><span class="n">scale_counts</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">scale_counts</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors_scale</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">ax5</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Number of Methods</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax5</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Scalability to Large Datasets</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="sh">'</span><span class="s">bold</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax5</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># 6. Requires k pre-specification
</span><span class="n">ax6</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="nf">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">req_k_counts</span> <span class="o">=</span> <span class="n">comparison</span><span class="p">[</span><span class="sh">'</span><span class="s">Requires k</span><span class="sh">'</span><span class="p">].</span><span class="nf">value_counts</span><span class="p">()</span>
<span class="n">ax6</span><span class="p">.</span><span class="nf">pie</span><span class="p">(</span><span class="n">req_k_counts</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">req_k_counts</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">autopct</span><span class="o">=</span><span class="sh">'</span><span class="s">%1.0f%%</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">colors</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">#A23B72</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">#1B998B</span><span class="sh">'</span><span class="p">],</span> <span class="n">startangle</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">ax6</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Requires k Pre-specification</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="sh">'</span><span class="s">bold</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># 7. Method-wise optimal k
</span><span class="n">ax7</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="nf">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:])</span>
<span class="n">methods</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">all_results</span><span class="p">.</span><span class="nf">keys</span><span class="p">())</span>
<span class="n">ks</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">all_results</span><span class="p">.</span><span class="nf">values</span><span class="p">())</span>
<span class="n">colors_methods</span> <span class="o">=</span> <span class="p">[</span><span class="n">category_colors</span><span class="p">[</span><span class="n">comparison</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">comparison</span><span class="p">[</span><span class="sh">'</span><span class="s">Method</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">m</span><span class="p">,</span> <span class="sh">'</span><span class="s">Category</span><span class="sh">'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> 
                  <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">methods</span><span class="p">]</span>
<span class="n">bars</span> <span class="o">=</span> <span class="n">ax7</span><span class="p">.</span><span class="nf">barh</span><span class="p">(</span><span class="n">methods</span><span class="p">,</span> <span class="n">ks</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors_methods</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">ax7</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Optimal k</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax7</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Optimal k by Method (colored by category)</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="sh">'</span><span class="s">bold</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax7</span><span class="p">.</span><span class="nf">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">True k=3</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax7</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">ax7</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="sh">'</span><span class="s">assets/img/posts/clustering-methods/11-all-methods-comparison.png</span><span class="sh">'</span><span class="p">,</span>
            <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="sh">'</span><span class="s">tight</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/clustering-methods/11-all-methods-comparison-480.webp 480w,/assets/img/posts/clustering-methods/11-all-methods-comparison-800.webp 800w,/assets/img/posts/clustering-methods/11-all-methods-comparison-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/posts/clustering-methods/11-all-methods-comparison.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Comprehensive visual comparison of all 8 clustering validation methods across multiple dimensions. </div> <hr> <h2 id="decision-framework-which-methods-to-use">Decision Framework: Which Methods to Use?</h2> <p>After exploring 8 methods across 3 parts, you might be overwhelmed. Here‚Äôs my <strong>practical decision framework</strong> to guide your choice:</p> <h3 id="step-1-understand-your-data">Step 1: Understand Your Data</h3> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Ask yourself:
‚îú‚îÄ Sample size: n &lt; 1,000? 1,000-10,000? &gt; 10,000?
‚îú‚îÄ Dimensionality: d &lt; 10? 10-20? &gt; 20?
‚îú‚îÄ Expected cluster shape: Spherical? Arbitrary? Unknown?
‚îú‚îÄ Outliers present: Yes? No? Unknown?
‚îî‚îÄ Computational budget: Seconds? Minutes? Hours?
</code></pre></div></div> <h3 id="step-2-choose-methods-based-on-constraints">Step 2: Choose Methods Based on Constraints</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">recommend_methods</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">cluster_shape</span><span class="o">=</span><span class="sh">'</span><span class="s">unknown</span><span class="sh">'</span><span class="p">,</span> 
                     <span class="n">has_outliers</span><span class="o">=</span><span class="sh">'</span><span class="s">unknown</span><span class="sh">'</span><span class="p">,</span> <span class="n">time_budget</span><span class="o">=</span><span class="sh">'</span><span class="s">medium</span><span class="sh">'</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Recommend clustering validation methods based on data characteristics
    
    Parameters:
    -----------
    n_samples : int
        Number of samples
    n_features : int
        Number of features
    cluster_shape : str
        </span><span class="sh">'</span><span class="s">spherical</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">arbitrary</span><span class="sh">'</span><span class="s">, or </span><span class="sh">'</span><span class="s">unknown</span><span class="sh">'</span><span class="s">
    has_outliers : str
        </span><span class="sh">'</span><span class="s">yes</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">no</span><span class="sh">'</span><span class="s">, or </span><span class="sh">'</span><span class="s">unknown</span><span class="sh">'</span><span class="s">
    time_budget : str
        </span><span class="sh">'</span><span class="s">low</span><span class="sh">'</span><span class="s"> (&lt; 1 min), </span><span class="sh">'</span><span class="s">medium</span><span class="sh">'</span><span class="s"> (&lt; 10 min), </span><span class="sh">'</span><span class="s">high</span><span class="sh">'</span><span class="s"> (&gt; 10 min)
    
    Returns:
    --------
    dict : Recommended methods with priority
    </span><span class="sh">"""</span>
    <span class="n">recommendations</span> <span class="o">=</span> <span class="p">{</span>
        <span class="sh">'</span><span class="s">primary</span><span class="sh">'</span><span class="p">:</span> <span class="p">[],</span>
        <span class="sh">'</span><span class="s">secondary</span><span class="sh">'</span><span class="p">:</span> <span class="p">[],</span>
        <span class="sh">'</span><span class="s">avoid</span><span class="sh">'</span><span class="p">:</span> <span class="p">[]</span>
    <span class="p">}</span>
    
    <span class="c1"># Large datasets (n &gt; 10,000)
</span>    <span class="k">if</span> <span class="n">n_samples</span> <span class="o">&gt;</span> <span class="mi">10000</span><span class="p">:</span>
        <span class="n">recommendations</span><span class="p">[</span><span class="sh">'</span><span class="s">primary</span><span class="sh">'</span><span class="p">].</span><span class="nf">extend</span><span class="p">([</span>
            <span class="sh">'</span><span class="s">Elbow Method</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Calinski-Harabasz Index</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Davies-Bouldin Index</span><span class="sh">'</span>
        <span class="p">])</span>
        <span class="n">recommendations</span><span class="p">[</span><span class="sh">'</span><span class="s">avoid</span><span class="sh">'</span><span class="p">].</span><span class="nf">extend</span><span class="p">([</span>
            <span class="sh">'</span><span class="s">Silhouette Analysis</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Gap Statistic</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Dendrogram</span><span class="sh">'</span>
        <span class="p">])</span>
    
    <span class="c1"># Medium datasets (1,000 &lt; n &lt; 10,000)
</span>    <span class="k">elif</span> <span class="n">n_samples</span> <span class="o">&gt;</span> <span class="mi">1000</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">time_budget</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">medium</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">high</span><span class="sh">'</span><span class="p">]:</span>
            <span class="n">recommendations</span><span class="p">[</span><span class="sh">'</span><span class="s">primary</span><span class="sh">'</span><span class="p">].</span><span class="nf">extend</span><span class="p">([</span>
                <span class="sh">'</span><span class="s">Silhouette Analysis</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">Calinski-Harabasz Index</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">Gap Statistic</span><span class="sh">'</span>
            <span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">recommendations</span><span class="p">[</span><span class="sh">'</span><span class="s">primary</span><span class="sh">'</span><span class="p">].</span><span class="nf">extend</span><span class="p">([</span>
                <span class="sh">'</span><span class="s">Elbow Method</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">Calinski-Harabasz Index</span><span class="sh">'</span>
            <span class="p">])</span>
    
    <span class="c1"># Small datasets (n &lt; 1,000)
</span>    <span class="k">else</span><span class="p">:</span>
        <span class="n">recommendations</span><span class="p">[</span><span class="sh">'</span><span class="s">primary</span><span class="sh">'</span><span class="p">].</span><span class="nf">extend</span><span class="p">([</span>
            <span class="sh">'</span><span class="s">Silhouette Analysis</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Gap Statistic</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Dendrogram</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">BIC/AIC</span><span class="sh">'</span>
        <span class="p">])</span>
    
    <span class="c1"># High-dimensional data (d &gt; 20)
</span>    <span class="k">if</span> <span class="n">n_features</span> <span class="o">&gt;</span> <span class="mi">20</span><span class="p">:</span>
        <span class="n">recommendations</span><span class="p">[</span><span class="sh">'</span><span class="s">avoid</span><span class="sh">'</span><span class="p">].</span><span class="nf">extend</span><span class="p">([</span>
            <span class="sh">'</span><span class="s">DBSCAN</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Dendrogram</span><span class="sh">'</span>
        <span class="p">])</span>
        <span class="n">recommendations</span><span class="p">[</span><span class="sh">'</span><span class="s">secondary</span><span class="sh">'</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">PCA + any method</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="c1"># Non-spherical clusters expected
</span>    <span class="k">if</span> <span class="n">cluster_shape</span> <span class="o">==</span> <span class="sh">'</span><span class="s">arbitrary</span><span class="sh">'</span><span class="p">:</span>
        <span class="n">recommendations</span><span class="p">[</span><span class="sh">'</span><span class="s">primary</span><span class="sh">'</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">DBSCAN</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">recommendations</span><span class="p">[</span><span class="sh">'</span><span class="s">primary</span><span class="sh">'</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">Dendrogram</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">recommendations</span><span class="p">[</span><span class="sh">'</span><span class="s">avoid</span><span class="sh">'</span><span class="p">].</span><span class="nf">extend</span><span class="p">([</span>
            <span class="sh">'</span><span class="s">Davies-Bouldin Index</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Calinski-Harabasz Index</span><span class="sh">'</span>
        <span class="p">])</span>
    
    <span class="c1"># Spherical clusters expected
</span>    <span class="k">elif</span> <span class="n">cluster_shape</span> <span class="o">==</span> <span class="sh">'</span><span class="s">spherical</span><span class="sh">'</span><span class="p">:</span>
        <span class="n">recommendations</span><span class="p">[</span><span class="sh">'</span><span class="s">primary</span><span class="sh">'</span><span class="p">].</span><span class="nf">extend</span><span class="p">([</span>
            <span class="sh">'</span><span class="s">Calinski-Harabasz Index</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Davies-Bouldin Index</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">BIC/AIC</span><span class="sh">'</span>
        <span class="p">])</span>
    
    <span class="c1"># Outliers present
</span>    <span class="k">if</span> <span class="n">has_outliers</span> <span class="o">==</span> <span class="sh">'</span><span class="s">yes</span><span class="sh">'</span><span class="p">:</span>
        <span class="n">recommendations</span><span class="p">[</span><span class="sh">'</span><span class="s">primary</span><span class="sh">'</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">DBSCAN</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">recommendations</span><span class="p">[</span><span class="sh">'</span><span class="s">secondary</span><span class="sh">'</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">Remove outliers first</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="c1"># Remove duplicates
</span>    <span class="n">recommendations</span><span class="p">[</span><span class="sh">'</span><span class="s">primary</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">set</span><span class="p">(</span><span class="n">recommendations</span><span class="p">[</span><span class="sh">'</span><span class="s">primary</span><span class="sh">'</span><span class="p">]))</span>
    <span class="n">recommendations</span><span class="p">[</span><span class="sh">'</span><span class="s">secondary</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">set</span><span class="p">(</span><span class="n">recommendations</span><span class="p">[</span><span class="sh">'</span><span class="s">secondary</span><span class="sh">'</span><span class="p">]))</span>
    <span class="n">recommendations</span><span class="p">[</span><span class="sh">'</span><span class="s">avoid</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">set</span><span class="p">(</span><span class="n">recommendations</span><span class="p">[</span><span class="sh">'</span><span class="s">avoid</span><span class="sh">'</span><span class="p">]))</span>
    
    <span class="k">return</span> <span class="n">recommendations</span>

<span class="c1"># Example usage
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Recommendation for large dataset:</span><span class="sh">"</span><span class="p">)</span>
<span class="n">rec1</span> <span class="o">=</span> <span class="nf">recommend_methods</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
                        <span class="n">cluster_shape</span><span class="o">=</span><span class="sh">'</span><span class="s">spherical</span><span class="sh">'</span><span class="p">,</span> <span class="n">time_budget</span><span class="o">=</span><span class="sh">'</span><span class="s">low</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Primary:</span><span class="sh">"</span><span class="p">,</span> <span class="n">rec1</span><span class="p">[</span><span class="sh">'</span><span class="s">primary</span><span class="sh">'</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Avoid:</span><span class="sh">"</span><span class="p">,</span> <span class="n">rec1</span><span class="p">[</span><span class="sh">'</span><span class="s">avoid</span><span class="sh">'</span><span class="p">])</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Recommendation for small complex dataset:</span><span class="sh">"</span><span class="p">)</span>
<span class="n">rec2</span> <span class="o">=</span> <span class="nf">recommend_methods</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                        <span class="n">cluster_shape</span><span class="o">=</span><span class="sh">'</span><span class="s">arbitrary</span><span class="sh">'</span><span class="p">,</span> <span class="n">has_outliers</span><span class="o">=</span><span class="sh">'</span><span class="s">yes</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Primary:</span><span class="sh">"</span><span class="p">,</span> <span class="n">rec2</span><span class="p">[</span><span class="sh">'</span><span class="s">primary</span><span class="sh">'</span><span class="p">])</span>
</code></pre></div></div> <h3 id="step-3-workflow-flowchart">Step 3: Workflow Flowchart</h3> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>START
  ‚îÇ
  ‚îú‚îÄ Is n &gt; 10,000?
  ‚îÇ   ‚îú‚îÄ YES ‚Üí Use: Elbow, Calinski-Harabasz, Davies-Bouldin
  ‚îÇ   ‚îî‚îÄ NO  ‚Üí Continue
  ‚îÇ
  ‚îú‚îÄ Know cluster shape?
  ‚îÇ   ‚îú‚îÄ Spherical     ‚Üí Calinski-Harabasz, Davies-Bouldin, BIC/AIC
  ‚îÇ   ‚îú‚îÄ Arbitrary     ‚Üí DBSCAN, Dendrogram, Silhouette
  ‚îÇ   ‚îî‚îÄ Unknown       ‚Üí Try multiple approaches
  ‚îÇ
  ‚îú‚îÄ Have outliers?
  ‚îÇ   ‚îú‚îÄ YES ‚Üí DBSCAN (auto noise detection)
  ‚îÇ   ‚îî‚îÄ NO  ‚Üí Continue
  ‚îÇ
  ‚îú‚îÄ Need statistical rigor?
  ‚îÇ   ‚îú‚îÄ YES ‚Üí Gap Statistic, BIC/AIC
  ‚îÇ   ‚îî‚îÄ NO  ‚Üí Elbow, Silhouette
  ‚îÇ
  ‚îú‚îÄ Time budget?
  ‚îÇ   ‚îú‚îÄ Low    ‚Üí Elbow, Calinski-Harabasz
  ‚îÇ   ‚îú‚îÄ Medium ‚Üí + Silhouette, BIC/AIC
  ‚îÇ   ‚îî‚îÄ High   ‚Üí + Gap Statistic, Dendrogram
  ‚îÇ
  ‚îî‚îÄ ALWAYS: Use 3-5 methods for consensus validation
</code></pre></div></div> <hr> <h2 id="production-workflow-from-exploration-to-deployment">Production Workflow: From Exploration to Deployment</h2> <p>Here‚Äôs a complete, production-ready workflow:</p> <h3 id="phase-1-exploratory-analysis-quick">Phase 1: Exploratory Analysis (Quick)</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ClusterExplorer</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Quick clustering exploration with multiple methods</span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">k_range</span><span class="o">=</span><span class="nf">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">11</span><span class="p">)):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="n">self</span><span class="p">.</span><span class="n">k_range</span> <span class="o">=</span> <span class="n">k_range</span>
        <span class="n">self</span><span class="p">.</span><span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
        
    <span class="k">def</span> <span class="nf">quick_screen</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Fast screening with 3 methods</span><span class="sh">"""</span>
        <span class="kn">from</span> <span class="n">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
        <span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="p">(</span><span class="n">calinski_harabasz_score</span><span class="p">,</span> 
                                     <span class="n">davies_bouldin_score</span><span class="p">)</span>
        <span class="kn">from</span> <span class="n">kneed</span> <span class="kn">import</span> <span class="n">KneeLocator</span>
        
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Running quick screening...</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="n">inertias</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">ch_scores</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">db_scores</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">k_range</span><span class="p">:</span>
            <span class="n">kmeans</span> <span class="o">=</span> <span class="nc">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="nf">fit_predict</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">X</span><span class="p">)</span>
            
            <span class="n">inertias</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">kmeans</span><span class="p">.</span><span class="n">inertia_</span><span class="p">)</span>
            <span class="n">ch_scores</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nf">calinski_harabasz_score</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>
            <span class="n">db_scores</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nf">davies_bouldin_score</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>
        
        <span class="c1"># Find optimal k for each method
</span>        <span class="n">kl</span> <span class="o">=</span> <span class="nc">KneeLocator</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">k_range</span><span class="p">),</span> <span class="n">inertias</span><span class="p">,</span> 
                        <span class="n">curve</span><span class="o">=</span><span class="sh">'</span><span class="s">convex</span><span class="sh">'</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="sh">'</span><span class="s">decreasing</span><span class="sh">'</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">results</span><span class="p">[</span><span class="sh">'</span><span class="s">elbow</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">kl</span><span class="p">.</span><span class="n">elbow</span>
        <span class="n">self</span><span class="p">.</span><span class="n">results</span><span class="p">[</span><span class="sh">'</span><span class="s">calinski_harabasz</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">k_range</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">ch_scores</span><span class="p">)]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">results</span><span class="p">[</span><span class="sh">'</span><span class="s">davies_bouldin</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">k_range</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">argmin</span><span class="p">(</span><span class="n">db_scores</span><span class="p">)]</span>
        
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">  Elbow: k=</span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">results</span><span class="p">[</span><span class="sh">'</span><span class="s">elbow</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">  Calinski-Harabasz: k=</span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">results</span><span class="p">[</span><span class="sh">'</span><span class="s">calinski_harabasz</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">  Davies-Bouldin: k=</span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">results</span><span class="p">[</span><span class="sh">'</span><span class="s">davies_bouldin</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">results</span>
    
    <span class="k">def</span> <span class="nf">get_consensus</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Get consensus k from quick screening</span><span class="sh">"""</span>
        <span class="kn">from</span> <span class="n">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
        <span class="n">ks</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">results</span><span class="p">.</span><span class="nf">values</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">]</span>
        <span class="n">mode_k</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="nf">mode</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">agreement</span> <span class="o">=</span> <span class="n">ks</span><span class="p">.</span><span class="nf">count</span><span class="p">(</span><span class="n">mode_k</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">ks</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">mode_k</span><span class="p">,</span> <span class="n">agreement</span>

<span class="c1"># Example usage
</span><span class="n">explorer</span> <span class="o">=</span> <span class="nc">ClusterExplorer</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>
<span class="n">quick_results</span> <span class="o">=</span> <span class="n">explorer</span><span class="p">.</span><span class="nf">quick_screen</span><span class="p">()</span>
<span class="n">consensus_k</span><span class="p">,</span> <span class="n">agreement</span> <span class="o">=</span> <span class="n">explorer</span><span class="p">.</span><span class="nf">get_consensus</span><span class="p">()</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="se">\n</span><span class="s">Quick consensus: k=</span><span class="si">{</span><span class="n">consensus_k</span><span class="si">}</span><span class="s"> (</span><span class="si">{</span><span class="n">agreement</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="s">% agreement)</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <h3 id="phase-2-detailed-validation-if-needed">Phase 2: Detailed Validation (If Needed)</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ClusterValidator</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Detailed validation with statistical rigor</span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">candidate_ks</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="n">self</span><span class="p">.</span><span class="n">candidate_ks</span> <span class="o">=</span> <span class="n">candidate_ks</span>
        <span class="n">self</span><span class="p">.</span><span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
        
    <span class="k">def</span> <span class="nf">detailed_validation</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Run computationally expensive methods</span><span class="sh">"""</span>
        <span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>
        <span class="kn">from</span> <span class="n">sklearn.mixture</span> <span class="kn">import</span> <span class="n">GaussianMixture</span>
        
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Running detailed validation...</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">candidate_ks</span><span class="p">:</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="se">\n</span><span class="s">Evaluating k=</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s">:</span><span class="sh">"</span><span class="p">)</span>
            
            <span class="c1"># Silhouette
</span>            <span class="n">kmeans</span> <span class="o">=</span> <span class="nc">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="nf">fit_predict</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">X</span><span class="p">)</span>
            <span class="n">sil</span> <span class="o">=</span> <span class="nf">silhouette_score</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">  Silhouette: </span><span class="si">{</span><span class="n">sil</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
            
            <span class="c1"># BIC/AIC
</span>            <span class="n">gmm</span> <span class="o">=</span> <span class="nc">GaussianMixture</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
            <span class="n">gmm</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">X</span><span class="p">)</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">  BIC: </span><span class="si">{</span><span class="n">gmm</span><span class="p">.</span><span class="nf">bic</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">X</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">  AIC: </span><span class="si">{</span><span class="n">gmm</span><span class="p">.</span><span class="nf">aic</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">X</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
            
            <span class="n">self</span><span class="p">.</span><span class="n">results</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                <span class="sh">'</span><span class="s">silhouette</span><span class="sh">'</span><span class="p">:</span> <span class="n">sil</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">bic</span><span class="sh">'</span><span class="p">:</span> <span class="n">gmm</span><span class="p">.</span><span class="nf">bic</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">X</span><span class="p">),</span>
                <span class="sh">'</span><span class="s">aic</span><span class="sh">'</span><span class="p">:</span> <span class="n">gmm</span><span class="p">.</span><span class="nf">aic</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">X</span><span class="p">)</span>
            <span class="p">}</span>
        
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">results</span>
    
    <span class="k">def</span> <span class="nf">recommend</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Make final recommendation</span><span class="sh">"""</span>
        <span class="c1"># Find best k for each metric
</span>        <span class="n">best_sil</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">results</span><span class="p">.</span><span class="nf">items</span><span class="p">(),</span> 
                      <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="sh">'</span><span class="s">silhouette</span><span class="sh">'</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">best_bic</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">results</span><span class="p">.</span><span class="nf">items</span><span class="p">(),</span>
                      <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="sh">'</span><span class="s">bic</span><span class="sh">'</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">best_aic</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">results</span><span class="p">.</span><span class="nf">items</span><span class="p">(),</span>
                      <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="sh">'</span><span class="s">aic</span><span class="sh">'</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="sh">"</span> <span class="o">+</span> <span class="sh">"</span><span class="s">=</span><span class="sh">"</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">FINAL RECOMMENDATION</span><span class="sh">"</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">=</span><span class="sh">"</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Best by Silhouette: k=</span><span class="si">{</span><span class="n">best_sil</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Best by BIC: k=</span><span class="si">{</span><span class="n">best_bic</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Best by AIC: k=</span><span class="si">{</span><span class="n">best_aic</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="c1"># Consensus
</span>        <span class="kn">from</span> <span class="n">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
        <span class="n">ks</span> <span class="o">=</span> <span class="p">[</span><span class="n">best_sil</span><span class="p">,</span> <span class="n">best_bic</span><span class="p">,</span> <span class="n">best_aic</span><span class="p">]</span>
        <span class="n">mode_k</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="nf">mode</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="se">\n</span><span class="s">Consensus recommendation: k=</span><span class="si">{</span><span class="n">mode_k</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">=</span><span class="sh">"</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">mode_k</span>

<span class="c1"># Example usage
</span><span class="k">if</span> <span class="n">agreement</span> <span class="o">&lt;</span> <span class="mf">0.7</span><span class="p">:</span>  <span class="c1"># If quick screening didn't reach consensus
</span>    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Low consensus detected. Running detailed validation...</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">validator</span> <span class="o">=</span> <span class="nc">ClusterValidator</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> 
                                 <span class="n">candidate_ks</span><span class="o">=</span><span class="p">[</span><span class="n">consensus_k</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">consensus_k</span><span class="p">,</span> <span class="n">consensus_k</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">detailed_results</span> <span class="o">=</span> <span class="n">validator</span><span class="p">.</span><span class="nf">detailed_validation</span><span class="p">()</span>
    <span class="n">final_k</span> <span class="o">=</span> <span class="n">validator</span><span class="p">.</span><span class="nf">recommend</span><span class="p">()</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">final_k</span> <span class="o">=</span> <span class="n">consensus_k</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="se">\n</span><span class="s">Strong consensus from quick screening. Recommended k=</span><span class="si">{</span><span class="n">final_k</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <h3 id="phase-3-production-deployment">Phase 3: Production Deployment</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ProductionClustering</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Production-ready clustering with validation</span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="sh">'</span><span class="s">kmeans</span><span class="sh">'</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="n">n_clusters</span>
        <span class="n">self</span><span class="p">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="n">self</span><span class="p">.</span><span class="n">scaler</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Fit clustering model</span><span class="sh">"""</span>
        <span class="c1"># Scale features
</span>        <span class="n">X_scaled</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">scaler</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        
        <span class="c1"># Train model
</span>        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">method</span> <span class="o">==</span> <span class="sh">'</span><span class="s">kmeans</span><span class="sh">'</span><span class="p">:</span>
            <span class="kn">from</span> <span class="n">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
            <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="nc">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">n_clusters</span><span class="p">,</span> 
                              <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">self</span><span class="p">.</span><span class="n">method</span> <span class="o">==</span> <span class="sh">'</span><span class="s">gmm</span><span class="sh">'</span><span class="p">:</span>
            <span class="kn">from</span> <span class="n">sklearn.mixture</span> <span class="kn">import</span> <span class="n">GaussianMixture</span>
            <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="nc">GaussianMixture</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">n_clusters</span><span class="p">,</span>
                                        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">self</span><span class="p">.</span><span class="n">method</span> <span class="o">==</span> <span class="sh">'</span><span class="s">dbscan</span><span class="sh">'</span><span class="p">:</span>
            <span class="kn">from</span> <span class="n">sklearn.cluster</span> <span class="kn">import</span> <span class="n">DBSCAN</span>
            <span class="c1"># Parameters should be tuned beforehand
</span>            <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="nc">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">min_samples</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>
        
        <span class="c1"># Compute quality metrics
</span>        <span class="n">labels</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">quality_metrics</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_compute_metrics</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">self</span>
    
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Predict cluster labels</span><span class="sh">"""</span>
        <span class="n">X_scaled</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">scaler</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">fit_predict</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_compute_metrics</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X_scaled</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Compute clustering quality metrics</span><span class="sh">"""</span>
        <span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="p">(</span><span class="n">silhouette_score</span><span class="p">,</span> 
                                     <span class="n">davies_bouldin_score</span><span class="p">,</span>
                                     <span class="n">calinski_harabasz_score</span><span class="p">)</span>
        
        <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">silhouette</span><span class="sh">'</span><span class="p">:</span> <span class="nf">silhouette_score</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">labels</span><span class="p">),</span>
            <span class="sh">'</span><span class="s">davies_bouldin</span><span class="sh">'</span><span class="p">:</span> <span class="nf">davies_bouldin_score</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">labels</span><span class="p">),</span>
            <span class="sh">'</span><span class="s">calinski_harabasz</span><span class="sh">'</span><span class="p">:</span> <span class="nf">calinski_harabasz_score</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">labels</span><span class="p">),</span>
            <span class="sh">'</span><span class="s">n_clusters</span><span class="sh">'</span><span class="p">:</span> <span class="nf">len</span><span class="p">(</span><span class="nf">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">in</span> <span class="n">labels</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
        <span class="p">}</span>
        
        <span class="k">return</span> <span class="n">metrics</span>
    
    <span class="k">def</span> <span class="nf">summary</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Print model summary</span><span class="sh">"""</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="sh">"</span> <span class="o">+</span> <span class="sh">"</span><span class="s">=</span><span class="sh">"</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">PRODUCTION MODEL SUMMARY</span><span class="sh">"</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">=</span><span class="sh">"</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Method: </span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">method</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Number of clusters: </span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">n_clusters</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Quality Metrics:</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">metric</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">quality_metrics</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">  </span><span class="si">{</span><span class="n">metric</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">value</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">=</span><span class="sh">"</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>

<span class="c1"># Deploy to production
</span><span class="n">prod_model</span> <span class="o">=</span> <span class="nc">ProductionClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">final_k</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="sh">'</span><span class="s">kmeans</span><span class="sh">'</span><span class="p">)</span>
<span class="n">prod_model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">prod_model</span><span class="p">.</span><span class="nf">summary</span><span class="p">()</span>

<span class="c1"># Save model
</span><span class="kn">import</span> <span class="n">joblib</span>
<span class="n">joblib</span><span class="p">.</span><span class="nf">dump</span><span class="p">(</span><span class="n">prod_model</span><span class="p">,</span> <span class="sh">'</span><span class="s">clustering_model.pkl</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Model saved to: clustering_model.pkl</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <hr> <h2 id="case-studies-different-data-types">Case Studies: Different Data Types</h2> <p>Let‚Äôs see how to apply our framework to different real-world scenarios:</p> <h3 id="case-study-1-customer-segmentation-tabular-data">Case Study 1: Customer Segmentation (Tabular Data)</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simulated customer data
</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n_customers</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># Features: age, income, spending_score, tenure
</span><span class="n">customers</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">column_stack</span><span class="p">([</span>
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="n">n_customers</span><span class="p">),</span>  <span class="c1"># age
</span>    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">20000</span><span class="p">,</span> <span class="n">n_customers</span><span class="p">),</span>  <span class="c1"># income
</span>    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="n">n_customers</span><span class="p">),</span>  <span class="c1"># spending score
</span>    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n_customers</span><span class="p">)</span>  <span class="c1"># tenure (years)
</span><span class="p">])</span>

<span class="n">customers_scaled</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">().</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">customers</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Customer Segmentation Analysis</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">=</span><span class="sh">"</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>

<span class="c1"># Quick screening
</span><span class="n">explorer</span> <span class="o">=</span> <span class="nc">ClusterExplorer</span><span class="p">(</span><span class="n">customers_scaled</span><span class="p">,</span> <span class="n">k_range</span><span class="o">=</span><span class="nf">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">explorer</span><span class="p">.</span><span class="nf">quick_screen</span><span class="p">()</span>
<span class="n">k</span><span class="p">,</span> <span class="n">agreement</span> <span class="o">=</span> <span class="n">explorer</span><span class="p">.</span><span class="nf">get_consensus</span><span class="p">()</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="se">\n</span><span class="s">Recommended segments: </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Use case: Create </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s"> customer personas for targeted marketing</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <h3 id="case-study-2-image-compression-high-dimensional">Case Study 2: Image Compression (High-Dimensional)</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simulated image pixels (e.g., for color quantization)
</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n_pixels</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">n_colors</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># RGB
</span>
<span class="c1"># Generate image with 5 dominant colors
</span><span class="n">image_pixels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">vstack</span><span class="p">([</span>
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">([</span><span class="mi">200</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span> <span class="mi">20</span><span class="p">,</span> <span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="n">n_colors</span><span class="p">)),</span>   <span class="c1"># Red
</span>    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">([</span><span class="mi">50</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span> <span class="mi">20</span><span class="p">,</span> <span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="n">n_colors</span><span class="p">)),</span>   <span class="c1"># Green
</span>    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">([</span><span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span> <span class="mi">20</span><span class="p">,</span> <span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="n">n_colors</span><span class="p">)),</span>   <span class="c1"># Blue
</span>    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">([</span><span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span> <span class="mi">20</span><span class="p">,</span> <span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="n">n_colors</span><span class="p">)),</span>  <span class="c1"># Yellow
</span>    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">([</span><span class="mi">200</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span> <span class="mi">20</span><span class="p">,</span> <span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="n">n_colors</span><span class="p">))</span>   <span class="c1"># Magenta
</span><span class="p">])</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Image Color Quantization</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">=</span><span class="sh">"</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>

<span class="c1"># For image compression, use fast methods (millions of pixels)
</span><span class="kn">from</span> <span class="n">sklearn.cluster</span> <span class="kn">import</span> <span class="n">MiniBatchKMeans</span>

<span class="n">inertias</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">16</span><span class="p">):</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="nc">MiniBatchKMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">kmeans</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">image_pixels</span><span class="p">)</span>
    <span class="n">inertias</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">kmeans</span><span class="p">.</span><span class="n">inertia_</span><span class="p">)</span>

<span class="n">kl</span> <span class="o">=</span> <span class="nc">KneeLocator</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="n">inertias</span><span class="p">,</span> <span class="n">curve</span><span class="o">=</span><span class="sh">'</span><span class="s">convex</span><span class="sh">'</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="sh">'</span><span class="s">decreasing</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Optimal colors for compression: </span><span class="si">{</span><span class="n">kl</span><span class="p">.</span><span class="n">elbow</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Use case: Reduce image to </span><span class="si">{</span><span class="n">kl</span><span class="p">.</span><span class="n">elbow</span><span class="si">}</span><span class="s"> colors for faster transmission</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <h3 id="case-study-3-anomaly-detection-with-outliers">Case Study 3: Anomaly Detection (With Outliers)</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simulated network traffic data with anomalies
</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n_normal</span> <span class="o">=</span> <span class="mi">900</span>
<span class="n">n_anomaly</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># Normal traffic: 2 patterns
</span><span class="n">normal_traffic</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">vstack</span><span class="p">([</span>
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span> <span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="mi">450</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>   <span class="c1"># Pattern 1
</span>    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">([</span><span class="mi">200</span><span class="p">,</span> <span class="mi">150</span><span class="p">],</span> <span class="mi">15</span><span class="p">,</span> <span class="p">(</span><span class="mi">450</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>   <span class="c1"># Pattern 2
</span><span class="p">])</span>

<span class="c1"># Anomalous traffic: scattered
</span><span class="n">anomaly_traffic</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">300</span><span class="p">,</span> <span class="mi">300</span><span class="p">],</span> <span class="p">(</span><span class="n">n_anomaly</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

<span class="n">traffic_data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">vstack</span><span class="p">([</span><span class="n">normal_traffic</span><span class="p">,</span> <span class="n">anomaly_traffic</span><span class="p">])</span>
<span class="n">traffic_scaled</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">().</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">traffic_data</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Network Anomaly Detection</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">=</span><span class="sh">"</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>

<span class="c1"># DBSCAN excels with outliers
</span><span class="kn">from</span> <span class="n">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">NearestNeighbors</span>

<span class="n">k</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">nbrs</span> <span class="o">=</span> <span class="nc">NearestNeighbors</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">).</span><span class="nf">fit</span><span class="p">(</span><span class="n">traffic_scaled</span><span class="p">)</span>
<span class="n">distances</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nbrs</span><span class="p">.</span><span class="nf">kneighbors</span><span class="p">(</span><span class="n">traffic_scaled</span><span class="p">)</span>
<span class="n">distances</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sort</span><span class="p">(</span><span class="n">distances</span><span class="p">[:,</span> <span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># Find elbow in k-distance plot
</span><span class="n">kl</span> <span class="o">=</span> <span class="nc">KneeLocator</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">distances</span><span class="p">)),</span> <span class="n">distances</span><span class="p">,</span> 
                 <span class="n">curve</span><span class="o">=</span><span class="sh">'</span><span class="s">convex</span><span class="sh">'</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="sh">'</span><span class="s">increasing</span><span class="sh">'</span><span class="p">)</span>
<span class="n">optimal_eps</span> <span class="o">=</span> <span class="n">distances</span><span class="p">[</span><span class="n">kl</span><span class="p">.</span><span class="n">elbow</span><span class="p">]</span> <span class="k">if</span> <span class="n">kl</span><span class="p">.</span><span class="n">elbow</span> <span class="k">else</span> <span class="mf">0.3</span>

<span class="n">dbscan</span> <span class="o">=</span> <span class="nc">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="n">optimal_eps</span><span class="p">,</span> <span class="n">min_samples</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">dbscan</span><span class="p">.</span><span class="nf">fit_predict</span><span class="p">(</span><span class="n">traffic_scaled</span><span class="p">)</span>

<span class="n">n_clusters</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="nf">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">in</span> <span class="n">labels</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">n_noise</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">labels</span><span class="p">).</span><span class="nf">count</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Normal traffic patterns detected: </span><span class="si">{</span><span class="n">n_clusters</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Anomalies detected: </span><span class="si">{</span><span class="n">n_noise</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Use case: Flag </span><span class="si">{</span><span class="n">n_noise</span><span class="si">}</span><span class="s"> suspicious network connections for review</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <hr> <h2 id="key-takeaways--best-practices">Key Takeaways &amp; Best Practices</h2> <p>After this comprehensive journey through 8 clustering validation methods, here are the essential lessons:</p> <h3 id="1-no-single-method-rules-them-all">1. No Single Method Rules Them All</h3> <p><strong>Different methods excel in different scenarios:</strong></p> <ul> <li>Fast exploration ‚Üí Elbow, Calinski-Harabasz</li> <li>Statistical rigor ‚Üí Gap Statistic, BIC/AIC</li> <li>Visual interpretation ‚Üí Dendrogram, Silhouette plots</li> <li>Arbitrary shapes ‚Üí DBSCAN, Dendrogram</li> <li>Outlier handling ‚Üí DBSCAN</li> </ul> <p><strong>Always use 3-5 methods</strong> for robust validation.</p> <h3 id="2-consensus--individual-results">2. Consensus &gt; Individual Results</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Bad practice
</span><span class="n">k</span> <span class="o">=</span> <span class="nf">elbow_method</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c1"># Relying on single method
</span>
<span class="c1"># Good practice
</span><span class="n">k_elbow</span> <span class="o">=</span> <span class="nf">elbow_method</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">k_silhouette</span> <span class="o">=</span> <span class="nf">silhouette_method</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">k_gap</span> <span class="o">=</span> <span class="nf">gap_statistic</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">k_calinski</span> <span class="o">=</span> <span class="nf">calinski_harabasz_method</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Take consensus
</span><span class="kn">from</span> <span class="n">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="n">k_final</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="nf">mode</span><span class="p">([</span><span class="n">k_elbow</span><span class="p">,</span> <span class="n">k_silhouette</span><span class="p">,</span> <span class="n">k_gap</span><span class="p">,</span> <span class="n">k_calinski</span><span class="p">])[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div> <h3 id="3-domain-knowledge-is-crucial">3. Domain Knowledge is Crucial</h3> <p><strong>Statistical metrics guide, domain knowledge decides:</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Example: Customer segmentation
‚îú‚îÄ Methods suggest: k=7
‚îú‚îÄ Business constraint: Only 3 marketing teams
‚îî‚îÄ Final decision: k=3 (align with resources)

Example: Gene expression clustering
‚îú‚îÄ Methods suggest: k=5
‚îú‚îÄ Biological knowledge: 3 known cell types
‚îî‚îÄ Investigate: k=5 might reveal 2 new subtypes!
</code></pre></div></div> <h3 id="4-data-preprocessing-matters">4. Data Preprocessing Matters</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Always scale features
</span><span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">().</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Consider dimensionality reduction for high-d data
</span><span class="kn">from</span> <span class="n">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="k">if</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">20</span><span class="p">:</span>
    <span class="n">pca</span> <span class="o">=</span> <span class="nc">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>  <span class="c1"># Keep 95% variance
</span>    <span class="n">X_reduced</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>
</code></pre></div></div> <h3 id="5-validate-with-external-metrics">5. Validate with External Metrics</h3> <p>If you have ground truth labels (even for a subset):</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="p">(</span><span class="n">adjusted_rand_score</span><span class="p">,</span> 
                             <span class="n">adjusted_mutual_info_score</span><span class="p">,</span>
                             <span class="n">normalized_mutual_info_score</span><span class="p">)</span>

<span class="c1"># Compare predicted vs true labels
</span><span class="n">ari</span> <span class="o">=</span> <span class="nf">adjusted_rand_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">ami</span> <span class="o">=</span> <span class="nf">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">nmi</span> <span class="o">=</span> <span class="nf">normalized_mutual_info_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">ARI: </span><span class="si">{</span><span class="n">ari</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>  <span class="c1"># 1=perfect, 0=random
</span><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">AMI: </span><span class="si">{</span><span class="n">ami</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">NMI: </span><span class="si">{</span><span class="n">nmi</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <h3 id="6-cluster-stability-matters">6. Cluster Stability Matters</h3> <p>Test if clusters are stable:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="k">def</span> <span class="nf">cluster_stability</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">n_runs</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Test clustering stability across multiple runs</span><span class="sh">"""</span>
    <span class="n">labels_list</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_runs</span><span class="p">):</span>
        <span class="n">kmeans</span> <span class="o">=</span> <span class="nc">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Single init
</span>        <span class="n">labels</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="nf">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">labels_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
    
    <span class="c1"># Average ARI between all pairs
</span>    <span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">adjusted_rand_score</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_runs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_runs</span><span class="p">):</span>
            <span class="n">scores</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nf">adjusted_rand_score</span><span class="p">(</span><span class="n">labels_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> 
                                             <span class="n">labels_list</span><span class="p">[</span><span class="n">j</span><span class="p">]))</span>
    
    <span class="n">avg_stability</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Clustering stability (k=</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s">): </span><span class="si">{</span><span class="n">avg_stability</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">avg_stability</span>

<span class="c1"># Test k=2 vs k=3
</span><span class="n">stability_2</span> <span class="o">=</span> <span class="nf">cluster_stability</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">stability_3</span> <span class="o">=</span> <span class="nf">cluster_stability</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div> <h3 id="7-document-your-decision-process">7. Document Your Decision Process</h3> <p><strong>For reproducibility and transparency:</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clustering_report</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">2024-01-29</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">dataset</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">iris</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">n_samples</span><span class="sh">'</span><span class="p">:</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">n_features</span><span class="sh">'</span><span class="p">:</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">methods_used</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">elbow</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">silhouette</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">gap_statistic</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">dbscan</span><span class="sh">'</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">results</span><span class="sh">'</span><span class="p">:</span> <span class="p">{</span>
        <span class="sh">'</span><span class="s">elbow</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">silhouette</span><span class="sh">'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">gap_statistic</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">dbscan</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span>
    <span class="p">},</span>
    <span class="sh">'</span><span class="s">consensus</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">final_decision</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">rationale</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">Strong consensus (75%) on k=3. Aligns with domain knowledge.</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">quality_metrics</span><span class="sh">'</span><span class="p">:</span> <span class="p">{</span>
        <span class="sh">'</span><span class="s">silhouette</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.5528</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">davies_bouldin</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.6619</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">calinski_harabasz</span><span class="sh">'</span><span class="p">:</span> <span class="mf">561.63</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Save report
</span><span class="kn">import</span> <span class="n">json</span>
<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">'</span><span class="s">clustering_report.json</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">w</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">json</span><span class="p">.</span><span class="nf">dump</span><span class="p">(</span><span class="n">clustering_report</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div> <hr> <h2 id="final-recommendations-your-clustering-toolkit">Final Recommendations: Your Clustering Toolkit</h2> <p>Based on everything we‚Äôve covered, here‚Äôs my recommended toolkit for different scenarios:</p> <h3 id="scenario-1-quick-business-analysis">Scenario 1: Quick Business Analysis</h3> <p><strong>Goal</strong>: Get insights fast for presentation</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Toolkit:
1. Elbow Method (visualization)
2. Calinski-Harabasz (single number to report)
3. Silhouette plots (show stakeholders cluster quality)

Time: ~5 minutes
</code></pre></div></div> <h3 id="scenario-2-academic-research">Scenario 2: Academic Research</h3> <p><strong>Goal</strong>: Publishable, rigorous analysis</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Toolkit:
1. Gap Statistic (formal hypothesis test)
2. Silhouette Analysis (detailed validation)
3. BIC/AIC (model selection framework)
4. Stability analysis (show robustness)

Time: ~30 minutes
Include: confidence intervals, sensitivity analysis
</code></pre></div></div> <h3 id="scenario-3-production-ml-pipeline">Scenario 3: Production ML Pipeline</h3> <p><strong>Goal</strong>: Automated, scalable, monitored</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Toolkit:
1. Quick screen: Elbow + Calinski-Harabasz
2. If consensus low: Add Gap Statistic
3. Deploy: Production class with monitoring
4. Track: Silhouette score over time (drift detection)

Time: ~10 minutes initial, automated thereafter
</code></pre></div></div> <h3 id="scenario-4-exploratory-data-analysis">Scenario 4: Exploratory Data Analysis</h3> <p><strong>Goal</strong>: Understand data structure</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Toolkit:
1. Dendrogram (visual hierarchy)
2. DBSCAN (discover arbitrary patterns)
3. Silhouette plots (detailed examination)
4. Multiple k values (explore alternatives)

Time: ~20 minutes
Focus: Understanding, not deciding
</code></pre></div></div> <hr> <h2 id="conclusion-the-journey-complete">Conclusion: The Journey Complete</h2> <p>I hope you found this series of articles is useful and you‚Äôve now mastered <strong>8 different methods</strong> for finding the optimal number of clusters, spanning:</p> <ul> <li> <strong>Visual methods</strong>: Elbow, Dendrogram</li> <li> <strong>Geometric methods</strong>: Silhouette, Davies-Bouldin</li> <li> <strong>Statistical methods</strong>: Calinski-Harabasz, Gap Statistic</li> <li> <strong>Probabilistic methods</strong>: BIC, AIC</li> <li> <strong>Density-based methods</strong>: DBSCAN</li> </ul> <h3 id="the-meta-lesson">The Meta-Lesson</h3> <p>The ultimate lesson isn‚Äôt about any single method - it‚Äôs about <strong>triangulation</strong>. In data science, as in navigation, you get your best bearing by taking readings from multiple angles.</p> <p><strong>No method is perfect. But together, they‚Äôre powerful.</strong></p> <h3 id="whats-next-for-you">What‚Äôs Next for You?</h3> <p>Now that you have this comprehensive toolkit:</p> <ol> <li> <strong>Practice on your own data</strong> - Try all 8 methods on a real project</li> <li> <strong>Build your intuition</strong> - Notice which methods agree/disagree and why</li> <li> <strong>Create your own framework</strong> - Adapt recommendations to your domain</li> <li> <strong>Share your findings</strong> - Write about your experiences</li> </ol> <h3 id="going-deeper">Going Deeper</h3> <p>Want to explore further?</p> <p><strong>Advanced topics to investigate:</strong></p> <ul> <li> <strong>Consensus clustering</strong>: Combine multiple clustering results</li> <li> <strong>Subspace clustering</strong>: Find clusters in feature subsets</li> <li> <strong>Time-series clustering</strong>: DTW distance, shape-based methods</li> <li> <strong>Deep clustering</strong>: Neural network-based approaches</li> <li> <strong>Ensemble methods</strong>: Cluster ensembles for robustness</li> </ul> <p><strong>Recommended reading:</strong></p> <ul> <li>Tibshirani et al. (2001) - Gap Statistic original paper</li> <li>Rousseeuw (1987) - Silhouettes original paper</li> <li>Ester et al. (1996) - DBSCAN original paper</li> <li>‚ÄúCluster Analysis‚Äù by Everitt et al. - Comprehensive textbook</li> </ul> <hr> <h2 id="series-wrap-up">Series Wrap-Up</h2> <p>This concludes our 3-part series on finding the optimal number of clusters:</p> <ul> <li> <strong>Part 1</strong>: Foundation methods - Quick, intuitive validation</li> <li> <strong>Part 2</strong>: Advanced statistics - Rigorous, mathematical approaches</li> <li> <strong>Part 3</strong>: Alternative methods - Flexible, discovery-oriented techniques</li> </ul> <h3 id="your-feedback-matters">Your Feedback Matters</h3> <p>This series was written to bridge the gap between theory and practice. Did it help you? What would you add? What was unclear?</p> <p>Drop a comment below, or reach out:</p> <ul> <li> <strong>LinkedIn</strong>: <a href="https://www.linkedin.com/in/randy-frans-fela/" rel="external nofollow noopener" target="_blank">Randy Frans Fela</a> </li> <li> <strong>Email</strong>: randyrff@gmail.com</li> </ul> <h3 id="special-thanks">Special Thanks</h3> <p>To my colleagues at Jabra who inspired many of these case studies, to the open-source community for incredible tools like scikit-learn, and to you for reading all the way to the end!</p> <h3 id="apply-this-knowledge">Apply This Knowledge</h3> <p>The best way to learn is by doing. Here‚Äôs your homework:</p> <ol> <li>Take a dataset you‚Äôre working with</li> <li>Apply 4-5 methods from this series</li> <li>Document your process</li> <li>Share your findings (blog post, talk, or just with your team)</li> </ol> <p><strong>I‚Äôd love to see what you discover!</strong></p> <hr> <h2 id="final-thoughts">Final Thoughts</h2> <p>In my work at Jabra, evaluating perceptual audio quality metrics, I use clustering daily. The methods in this series aren‚Äôt just academic exercises - they‚Äôre tools I rely on to make real decisions about product features.</p> <p>Your journey with clustering is just beginning. These 8 methods are your compass - use them wisely, combine them thoughtfully, and always remember:</p> <blockquote> <p>‚ÄúThe goal of clustering isn‚Äôt to find THE answer - it‚Äôs to understand your data well enough to ask better questions.‚Äù</p> </blockquote> <p>Happy clustering! üéØüöÄ</p> <hr> <p><em>Tags: #clustering #machinelearning #datascience #python #unsupervisedlearning #dbscan #hierarchicalclustering #bestpractices #production</em></p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://fransfela.substack.com/p/sound-horeg-antara-euforia-budaya" target="_blank" rel="external nofollow noopener">Just a moment...</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://medium.com/@fransfela/ffmpeg-what-it-is-and-how-to-install-it-on-your-machine-fb589318d117?source=rss-d87e2a60cec5------2" target="_blank" rel="external nofollow noopener">FFmpeg: What it is and how to install it on your machine</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://medium.com/@fransfela/ffmpeg-apa-itu-dan-bagaimana-cara-menginstalnya-di-mesin-anda-17590374a7b?source=rss-d87e2a60cec5------2" target="_blank" rel="external nofollow noopener">FFmpeg: Apa Itu dan Bagaimana Cara Menginstalnya di Mesin Anda</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://medium.com/@fransfela/statistical-design-of-experiment-01-an-introduction-98394af6c74c?source=rss-d87e2a60cec5------2" target="_blank" rel="external nofollow noopener">Statistical Design of Experiment 01: An Introduction</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/id-id/blog/2026/mentoring-bang-randy-scholarship-guidance/">MentoringBangRandy: Perjalanan dari Kuli Pabrik ke Denmark</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬©Copyright 2026 Randy F. Fela. | All rights reserved | Built with <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> and <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a> | <a href="/id-id/mentoring/">Mentoring Services</a> | Copenhagen, Denmark </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"> <div class="modal-footer" slot="footer"> <span class="help"> <svg version="1.0" class="ninja-examplekey" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 1280 1280"> <path d="M1013 376c0 73.4-.4 113.3-1.1 120.2a159.9 159.9 0 0 1-90.2 127.3c-20 9.6-36.7 14-59.2 15.5-7.1.5-121.9.9-255 1h-242l95.5-95.5 95.5-95.5-38.3-38.2-38.2-38.3-160 160c-88 88-160 160.4-160 161 0 .6 72 73 160 161l160 160 38.2-38.3 38.3-38.2-95.5-95.5-95.5-95.5h251.1c252.9 0 259.8-.1 281.4-3.6 72.1-11.8 136.9-54.1 178.5-116.4 8.6-12.9 22.6-40.5 28-55.4 4.4-12 10.7-36.1 13.1-50.6 1.6-9.6 1.8-21 2.1-132.8l.4-122.2H1013v110z"></path> </svg> to select </span> <span class="help"> <svg xmlns="http://www.w3.org/2000/svg" class="ninja-examplekey" viewbox="0 0 24 24"> <path d="M0 0h24v24H0V0z" fill="none"></path> <path d="M20 12l-1.41-1.41L13 16.17V4h-2v12.17l-5.58-5.59L4 12l8 8 8-8z"></path> </svg> <svg xmlns="http://www.w3.org/2000/svg" class="ninja-examplekey" viewbox="0 0 24 24"> <path d="M0 0h24v24H0V0z" fill="none"></path> <path d="M4 12l1.41 1.41L11 7.83V20h2V7.83l5.58 5.59L20 12l-8-8-8 8z"></path> </svg> to navigate </span> <span class="help"> <span class="ninja-examplekey esc">esc</span> to close </span> <span class="help"> <svg xmlns="http://www.w3.org/2000/svg" class="ninja-examplekey backspace" viewbox="0 0 20 20" fill="currentColor"> <path fill-rule="evenodd" d="M6.707 4.879A3 3 0 018.828 4H15a3 3 0 013 3v6a3 3 0 01-3 3H8.828a3 3 0 01-2.12-.879l-4.415-4.414a1 1 0 010-1.414l4.414-4.414zm4 2.414a1 1 0 00-1.414 1.414L10.586 10l-1.293 1.293a1 1 0 101.414 1.414L12 11.414l1.293 1.293a1 1 0 001.414-1.414L13.414 10l1.293-1.293a1 1 0 00-1.414-1.414L12 8.586l-1.293-1.293z" clip-rule="evenodd"></path> </svg> move to parent </span> </div> </ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/id-id/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>