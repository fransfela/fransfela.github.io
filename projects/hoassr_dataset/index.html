<!DOCTYPE html> <html lang="en-us"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> HOA-SSR Dataset | Dr. Randy F Fela </title> <meta name="author" content="Randy F. Fela"> <meta name="description" content="Higher-Order Ambisonics Sound Scene Repository - A comprehensive 360¬∞ audiovisual quality dataset for immersive media research"> <meta name="keywords" content="perception, audio-visual, research, data-science"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/bitmoji-closeup-icon.jpg?b942dbbe98713eee0832d224b9f7b36c"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://fransfela.github.io/projects/hoassr_dataset/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Dr. Randy F Fela </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"> EN-US </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/pt-br/projects/hoassr_dataset/"> PT-BR</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/fr-ca/projects/hoassr_dataset/"> FR-CA</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">HOA-SSR Dataset</h1> <p class="post-description">Higher-Order Ambisonics Sound Scene Repository - A comprehensive 360¬∞ audiovisual quality dataset for immersive media research</p> </header> <article> <p>The <strong>Higher-Order Ambisonics Sound Scene Repository (HOA-SSR)</strong> is a groundbreaking open-source dataset designed to advance research in perceptual quality evaluation of immersive 360¬∞ audiovisual content. This comprehensive dataset combines state-of-the-art spatial audio recording with ultra-high-definition 360¬∞ video, accompanied by subjective quality scores from trained assessors.</p> <h2 id="research-impact">Research Impact</h2> <p>To our knowledge, this is the first recorded audiovisual dataset with Mean Opinion Scores (MOS) specifically created to support perceptual quality research in immersive audiovisual content. The dataset opens new possibilities for developing and validating quality metrics for next-generation virtual reality, augmented reality, and immersive media applications.</p> <div class="alert alert-info mt-4"> <h5>üìä Dataset Highlights</h5> <ul class="mb-0"> <li> <strong>150+ audiovisual scenes</strong> captured in diverse real-world environments</li> <li> <strong>8K 360¬∞ video</strong> (7680√ó3840) at 30fps with YUV 4:2:2 color space</li> <li> <strong>4th order ambisonic audio</strong> (25 channels) at 48kHz, 24-bit</li> <li> <strong>Subjective quality scores</strong> from trained assessors</li> <li> <strong>Multiple quality metrics</strong> for both audio and video domains</li> </ul> </div> <h2 id="technical-specifications">Technical Specifications</h2> <h3 id="recording-equipment">Recording Equipment</h3> <p>The dataset was captured using professional-grade equipment to ensure the highest quality baseline:</p> <div class="row mt-3"> <div class="col-md-6"> <div class="card h-100"> <div class="card-body"> <h5 class="card-title">üé• Video Capture</h5> <p class="card-text"><strong>Insta360 Pro2</strong> - Professional spherical 360¬∞ camera with 6 synchronized lenses capturing every angle simultaneously</p> <ul class="small"> <li>Resolution: 8K (7680√ó3840)</li> <li>Frame rate: 30 fps</li> <li>Color depth: 8-bit YUV 4:2:2</li> <li>Format: Equirectangular projection (ERP)</li> </ul> </div> </div> </div> <div class="col-md-6"> <div class="card h-100"> <div class="card-body"> <h5 class="card-title">üéôÔ∏è Audio Capture</h5> <p class="card-text"><strong>em32 Eigenmike</strong> - Spherical microphone array with 32 omnidirectional microphones</p> <ul class="small"> <li>Order: 4th order ambisonics</li> <li>Channels: 25 (AmbiX B-format)</li> <li>Sample rate: 48 kHz</li> <li>Bit depth: 24-bit PCM</li> <li>Normalization: SN3D, ACN ordering</li> </ul> </div> </div> </div> </div> <h3 id="scene-diversity">Scene Diversity</h3> <p>The dataset contains audiovisual scenes with diverse characteristics including nature-mechanical, indoor-outdoor, static-dynamic, traffic-quiet, impulsive-steady, and speech-music variations. This diversity ensures broad applicability across different use cases and research questions.</p> <div class="row mt-4"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/hoassr-outdoor-480.webp 480w,/assets/img/projects/hoassr-outdoor-800.webp 800w,/assets/img/projects/hoassr-outdoor-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/hoassr-outdoor.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Outdoor scene capture" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/hoassr-indoor-480.webp 480w,/assets/img/projects/hoassr-indoor-800.webp 800w,/assets/img/projects/hoassr-indoor-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/hoassr-indoor.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Indoor scene capture" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/hoassr-urban-480.webp 480w,/assets/img/projects/hoassr-urban-800.webp 800w,/assets/img/projects/hoassr-urban-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/hoassr-urban.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Urban environment" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Representative scenes from the HOA-SSR dataset showcasing the diversity of recording environments. </div> <h2 id="subjective-quality-evaluation">Subjective Quality Evaluation</h2> <p>Three comprehensive subjective experiments were conducted to assess perceptual quality:</p> <h3 id="experimental-methodology">Experimental Methodology</h3> <div class="row mt-3"> <div class="col-md-4"> <div class="card border-primary h-100"> <div class="card-header bg-primary text-white"> <strong>Audio Quality Test</strong> </div> <div class="card-body"> <p class="small">Evaluated spatial audio fidelity and clarity using a 26-channel loudspeaker setup compliant with EBU 3276 and ITU-R BS.1116-3 standards</p> </div> </div> </div> <div class="col-md-4"> <div class="card border-success h-100"> <div class="card-header bg-success text-white"> <strong>Video Quality Test</strong> </div> <div class="card-body"> <p class="small">Assessed visual quality through head-mounted display (Samsung Odyssey+ Mixed Reality Headset) for immersive viewing</p> </div> </div> </div> <div class="col-md-4"> <div class="card border-info h-100"> <div class="card-header bg-info text-white"> <strong>Audiovisual Quality Test</strong> </div> <div class="card-body"> <p class="small">Combined evaluation of multimodal perceptual quality using synchronized audio-visual presentation</p> </div> </div> </div> </div> <p><strong>Protocol</strong>: Multiple Stimulus with Hidden Reference (MUSHRA-style) methodology<br> <strong>Participants</strong>: 20 trained assessors<br> <strong>Location</strong>: SenseLab Listening Test and VR facilities at FORCE Technology, Denmark<br> <strong>Ethics Approval</strong>: Danish Committee System on Health Research Ethics (Journal-nr H-20031815)</p> <h2 id="quality-metrics--analysis">Quality Metrics &amp; Analysis</h2> <h3 id="objective-quality-metrics-evaluated">Objective Quality Metrics Evaluated</h3> <p><strong>Audio Metrics:</strong></p> <ul> <li> <strong>PEAQ</strong> (Perceptual Evaluation of Audio Quality)</li> <li> <strong>ViSQOL</strong> (Virtual Speech Quality Objective Listener)</li> <li> <strong>AMBIQUAL</strong> (Ambisonic quality metric)</li> </ul> <p><strong>Video Metrics:</strong></p> <ul> <li>PSNR and variants (WS-PSNR, CPP-PSNR, S-PSNR)</li> <li>SSIM and MS-SSIM</li> <li>VMAF (2K and 4K variants)</li> </ul> <h3 id="encoding-parameters">Encoding Parameters</h3> <p>Audio was encoded at 16, 32, and 64 kbps per channel using AAC-LC encoder. Video was encoded using H.265/HEVC at three resolutions (1920√ó1080, 3840√ó1920, 6144√ó3072) and four quantization parameters (QP: 0, 22, 28, 34).</p> <div class="row justify-content-sm-center mt-4"> <div class="col-sm-10 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/hoassr-scores-480.webp 480w,/assets/img/projects/hoassr-scores-800.webp 800w,/assets/img/projects/hoassr-scores-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/hoassr-scores.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Subjective quality scores distribution" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Distribution of Mean Opinion Scores (MOS) across audio, video, and audiovisual experiments with 95% confidence intervals. </div> <h2 id="machine-learning-predictions">Machine Learning Predictions</h2> <p>Building on the subjective data, we developed predictive models for audiovisual quality assessment:</p> <h3 id="modeling-approach">Modeling Approach</h3> <p>Four regression-based machine learning models were trained and tested: multiple linear regression, decision tree, random forest, and support vector machine. Each model was constructed using combinations of audio and video quality metrics, producing 312 predictive models through cross-validation.</p> <p><strong>Key Findings:</strong></p> <ul> <li>The combination of VMAF and AMBIQUAL metrics proved most effective for audiovisual quality prediction</li> <li>Support Vector Machine achieved the highest performance with k-Fold cross-validation (PCC = 0.909, SROCC = 0.914, RMSE = 0.416)</li> <li>Machine learning approaches significantly outperformed simple linear models</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Example model architecture
</span><span class="kn">from</span> <span class="n">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>

<span class="c1"># Best performing configuration
</span><span class="n">model</span> <span class="o">=</span> <span class="nc">SVR</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="sh">'</span><span class="s">rbf</span><span class="sh">'</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">VMAF</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">AMBIQUAL</span><span class="sh">'</span><span class="p">]</span>  <span class="c1"># Audio-video metric fusion
</span><span class="n">cv</span> <span class="o">=</span> <span class="nc">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Achieved metrics:
# - Pearson Correlation: 0.909
# - Spearman Rank: 0.914
# - RMSE: 0.416
</span></code></pre></div></div> <h2 id="research-applications">Research Applications</h2> <p>The HOA-SSR dataset enables research across multiple domains:</p> <div class="row mt-3"> <div class="col-md-6 mt-3"> <h5>üéß Audio Product Development</h5> <ul> <li>Hearing aids and assistive devices testing</li> <li>True wireless stereo (TWS) earbuds evaluation</li> <li>Telecom headset quality assessment</li> <li>Spatial audio algorithm development</li> </ul> </div> <div class="col-md-6 mt-3"> <h5>ü§ñ AI &amp; Machine Learning</h5> <ul> <li>Training perceptual quality models</li> <li>Audio-visual fusion algorithms</li> <li>Scene understanding and classification</li> <li>Quality metric development and validation</li> </ul> </div> <div class="col-md-6 mt-3"> <h5>üéÆ Virtual Reality</h5> <ul> <li>Immersive experience quality evaluation</li> <li>Compression artifact assessment</li> <li>Codec performance benchmarking</li> <li>User experience optimization</li> </ul> </div> <div class="col-md-6 mt-3"> <h5>üìä Quality of Experience Research</h5> <ul> <li>Multimodal perception studies</li> <li>Cross-modal interaction analysis</li> <li>Standardization and benchmarking</li> <li>Quality metric correlation studies</li> </ul> </div> </div> <h2 id="experimental-design-optimization">Experimental Design Optimization</h2> <p>In follow-up research, we investigated efficient experimental design strategies:</p> <p><strong>Full Factorial Design (FFD) vs. Optimal Experimental Design (OED):</strong></p> <ul> <li>D-optimal design for factor screening</li> <li>I-optimal design for prediction accuracy</li> <li>Significant reduction in required test conditions while maintaining statistical power</li> <li>Applications in large-scale perceptual studies where FFD becomes impractical</li> </ul> <p>This work demonstrates how smart experimental design can reduce participant burden and testing time without compromising research validity.</p> <h2 id="collaboration--partners">Collaboration &amp; Partners</h2> <p>The HOA-SSR dataset is the result of a collaborative effort between leading research institutions and industry partners:</p> <p><strong>Research Partners:</strong></p> <ul> <li>Technical University of Denmark (DTU)</li> <li>FORCE Technology - SenseLab</li> <li>Nantes Universit√© (France)</li> </ul> <p><strong>Industry Partners:</strong></p> <ul> <li>Bang &amp; Olufsen</li> <li>Demant</li> <li>GN Store Nord (Jabra)</li> <li>Sonova</li> <li>WSA</li> <li>Additional industrial collaborators</li> </ul> <p><strong>Funding:</strong></p> <ul> <li>European Union Horizon 2020 Marie Sk≈Çodowska-Curie Actions (Grant No. 765911 - RealVision)</li> <li>Danish Ministry of Higher Education and Science</li> </ul> <h2 id="access--citation">Access &amp; Citation</h2> <h3 id="dataset-availability">Dataset Availability</h3> <p>The complete HOA-SSR dataset containing 150 audiovisual scenes is available for research and commercial use. The dataset can be purchased for full access, with partial access available for specific scenarios.</p> <p><strong>Contact</strong>: <a href="https://forcetechnology.com/en/services/acoustics-noise-sound-quality/senselab-download-hoa-ssr-dataset" rel="external nofollow noopener" target="_blank">FORCE Technology SenseLab</a></p> <h3 id="publications">Publications</h3> <p>If you use this dataset in your research, please cite the relevant publications:</p> <p><strong>Primary Dataset Paper:</strong></p> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@article</span><span class="p">{</span><span class="nl">fela2022perceptual</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{Perceptual Evaluation on Audio-visual Dataset of 360 Content}</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Fela, Randy Frans and Pastor, Andr{\'e}as and Le Callet, Patrick and Zacharov, Nick and Vigier, Toinon and Forchhammer, S{\o}ren}</span><span class="p">,</span>
  <span class="na">journal</span><span class="p">=</span><span class="s">{arXiv preprint arXiv:2205.08007}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="s">{2022}</span>
<span class="p">}</span>
</code></pre></div></div> <p><strong>Machine Learning Predictions:</strong></p> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@article</span><span class="p">{</span><span class="nl">fela2021perceptual</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{Perceptual Evaluation of 360 Audiovisual Quality and Machine Learning Predictions}</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Fela, Randy Frans and Zacharov, Nick and Forchhammer, S{\o}ren}</span><span class="p">,</span>
  <span class="na">journal</span><span class="p">=</span><span class="s">{arXiv preprint arXiv:2112.12273}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="s">{2021}</span>
<span class="p">}</span>
</code></pre></div></div> <p><strong>Experimental Design Optimization:</strong></p> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@article</span><span class="p">{</span><span class="nl">fela2023comparison</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{Comparison of Full Factorial and Optimal Experimental Design for Perceptual Evaluation of Audiovisual Quality}</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Fela, Randy Frans and Zacharov, Nick and Forchhammer, S{\o}ren}</span><span class="p">,</span>
  <span class="na">journal</span><span class="p">=</span><span class="s">{Journal of the Audio Engineering Society}</span><span class="p">,</span>
  <span class="na">volume</span><span class="p">=</span><span class="s">{71}</span><span class="p">,</span>
  <span class="na">number</span><span class="p">=</span><span class="s">{1/2}</span><span class="p">,</span>
  <span class="na">pages</span><span class="p">=</span><span class="s">{4--19}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="s">{2023}</span>
<span class="p">}</span>
</code></pre></div></div> <p><strong>Assessor Selection Methodology:</strong></p> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@article</span><span class="p">{</span><span class="nl">fela2022assessor</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{Assessor Selection Process for Perceptual Quality Evaluation of 360 Audiovisual Content}</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Fela, Randy Frans and Zacharov, Nick and Forchhammer, S{\o}ren}</span><span class="p">,</span>
  <span class="na">journal</span><span class="p">=</span><span class="s">{Journal of the Audio Engineering Society}</span><span class="p">,</span>
  <span class="na">volume</span><span class="p">=</span><span class="s">{70}</span><span class="p">,</span>
  <span class="na">number</span><span class="p">=</span><span class="s">{10}</span><span class="p">,</span>
  <span class="na">pages</span><span class="p">=</span><span class="s">{824--842}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="s">{2022}</span>
<span class="p">}</span>
</code></pre></div></div> <h2 id="technical-documentation">Technical Documentation</h2> <p>For researchers implementing models or reproducing results:</p> <ol> <li> <strong>Audio Decoding</strong>: 4th order ambisonics decoded to 26-channel configuration</li> <li> <strong>Video Rendering</strong>: Equirectangular to viewport projection with proper field of view</li> <li> <strong>Synchronization</strong>: Audio-visual temporal alignment critical for multimodal evaluation</li> <li> <strong>Metric Computation</strong>: Frame-level metrics aggregated using temporal pooling</li> </ol> <p>Detailed specifications and processing pipelines are available in the accompanying technical papers.</p> <hr> <p><strong>Status</strong>: Dataset Available<br> <strong>Version</strong>: 2.0<br> <strong>Last Updated</strong>: 2022<br> <strong>Related Papers</strong>:</p> <ul> <li> <a href="https://arxiv.org/abs/2205.08007" rel="external nofollow noopener" target="_blank">arXiv:2205.08007</a> - Primary Dataset Paper</li> <li> <a href="https://aes2.org/publications/elibrary-page/?id=22027" rel="external nofollow noopener" target="_blank">JAES 2023</a> - Experimental Design Comparison</li> <li> <a href="https://www.aes.org/e-lib/browse.cfm?elib=22010" rel="external nofollow noopener" target="_blank">JAES 2022</a> - Assessor Selection Process <strong>Dataset URL</strong>: <a href="https://forcetechnology.com/en/services/acoustics-noise-sound-quality/senselab-download-hoa-ssr-dataset" rel="external nofollow noopener" target="_blank">FORCE Technology</a> </li> </ul> <p>The HOA-SSR dataset represents a significant contribution to the field of immersive media quality assessment, enabling researchers worldwide to develop and validate next-generation quality metrics and perceptual models for 360¬∞ audiovisual content.</p> </article> <h2>References</h2> <div class="publications"> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬©Copyright 2026 Randy F. Fela. | All rights reserved | Built with <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> and <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a> | Copenhagen, Denmark </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"> <div class="modal-footer" slot="footer"> <span class="help"> <svg version="1.0" class="ninja-examplekey" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 1280 1280"> <path d="M1013 376c0 73.4-.4 113.3-1.1 120.2a159.9 159.9 0 0 1-90.2 127.3c-20 9.6-36.7 14-59.2 15.5-7.1.5-121.9.9-255 1h-242l95.5-95.5 95.5-95.5-38.3-38.2-38.2-38.3-160 160c-88 88-160 160.4-160 161 0 .6 72 73 160 161l160 160 38.2-38.3 38.3-38.2-95.5-95.5-95.5-95.5h251.1c252.9 0 259.8-.1 281.4-3.6 72.1-11.8 136.9-54.1 178.5-116.4 8.6-12.9 22.6-40.5 28-55.4 4.4-12 10.7-36.1 13.1-50.6 1.6-9.6 1.8-21 2.1-132.8l.4-122.2H1013v110z"></path> </svg> to select </span> <span class="help"> <svg xmlns="http://www.w3.org/2000/svg" class="ninja-examplekey" viewbox="0 0 24 24"> <path d="M0 0h24v24H0V0z" fill="none"></path> <path d="M20 12l-1.41-1.41L13 16.17V4h-2v12.17l-5.58-5.59L4 12l8 8 8-8z"></path> </svg> <svg xmlns="http://www.w3.org/2000/svg" class="ninja-examplekey" viewbox="0 0 24 24"> <path d="M0 0h24v24H0V0z" fill="none"></path> <path d="M4 12l1.41 1.41L11 7.83V20h2V7.83l5.58 5.59L20 12l-8-8-8 8z"></path> </svg> to navigate </span> <span class="help"> <span class="ninja-examplekey esc">esc</span> to close </span> <span class="help"> <svg xmlns="http://www.w3.org/2000/svg" class="ninja-examplekey backspace" viewbox="0 0 20 20" fill="currentColor"> <path fill-rule="evenodd" d="M6.707 4.879A3 3 0 018.828 4H15a3 3 0 013 3v6a3 3 0 01-3 3H8.828a3 3 0 01-2.12-.879l-4.415-4.414a1 1 0 010-1.414l4.414-4.414zm4 2.414a1 1 0 00-1.414 1.414L10.586 10l-1.293 1.293a1 1 0 101.414 1.414L12 11.414l1.293 1.293a1 1 0 001.414-1.414L13.414 10l1.293-1.293a1 1 0 00-1.414-1.414L12 8.586l-1.293-1.293z" clip-rule="evenodd"></path> </svg> move to parent </span> </div> </ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>