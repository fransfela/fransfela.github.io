# File: _jupyter/2025-01-09-cluster-analysis-intro.ipynb

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title: \"Finding the Right Number of Clusters: A Practical Guide\"\n",
    "date: 2025-01-09 10:00:00\n",
    "description: Learn how to determine optimal cluster numbers using Elbow Method and Silhouette Analysis with Python\n",
    "tags: machine-learning clustering data-science python\n",
    "categories: tutorials\n",
    "giscus_comments: true\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Right Number of Clusters\n",
    "\n",
    "One of the most common questions in cluster analysis is: **\"How many clusters should I use?\"** \n",
    "\n",
    "In this post, I'll show you two fundamental methods to answer this question:\n",
    "1. **Elbow Method** - Visual approach\n",
    "2. **Silhouette Analysis** - Quantitative approach\n",
    "\n",
    "We'll use the classic Iris dataset and Python's scikit-learn library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import our libraries and load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "# Set style for better-looking plots\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "\n",
    "# Standardize features (important for clustering!)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"Dataset shape: {X_scaled.shape}\")\n",
    "print(f\"Features: {iris.feature_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Elbow Method\n",
    "\n",
    "The Elbow Method plots the **Within-Cluster Sum of Squares (WCSS)** against the number of clusters. \n",
    "\n",
    "**How it works:**\n",
    "- WCSS measures how tight the clusters are\n",
    "- As we increase k, WCSS decreases\n",
    "- We look for the \"elbow\" where the decrease slows down\n",
    "\n",
    "**Formula:** \n",
    "$$WCSS(k) = \\sum_{i=1}^{k} \\sum_{x \\in C_i} ||x - \\mu_i||^2$$\n",
    "\n",
    "where $\\mu_i$ is the centroid of cluster $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate WCSS for different k values\n",
    "k_range = range(2, 11)\n",
    "wcss = []\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "    print(f\"k={k}: WCSS = {kmeans.inertia_:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Elbow curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, wcss, 'bo-', linewidth=2, markersize=10)\n",
    "plt.xlabel('Number of Clusters (k)', fontsize=12)\n",
    "plt.ylabel('WCSS (Within-Cluster Sum of Squares)', fontsize=12)\n",
    "plt.title('Elbow Method for Optimal k', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Mark the elbow point (k=3 for Iris)\n",
    "plt.axvline(x=3, color='r', linestyle='--', label='Elbow at k=3')\n",
    "plt.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** \n",
    "Looking at the plot, we can see the \"elbow\" appears around **k=3**. After this point, adding more clusters doesn't significantly reduce WCSS.\n",
    "\n",
    "For the Iris dataset, this makes sense - it contains 3 species of flowers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Silhouette Analysis\n",
    "\n",
    "The Silhouette Score measures **how similar a point is to its own cluster compared to other clusters**.\n",
    "\n",
    "**Formula:** \n",
    "$$s(i) = \\frac{b(i) - a(i)}{\\max\\{a(i), b(i)\\}}$$\n",
    "\n",
    "where:\n",
    "- $a(i)$ = average distance to points in same cluster\n",
    "- $b(i)$ = average distance to points in nearest cluster\n",
    "\n",
    "**Score range:**\n",
    "- **+1**: Perfect clustering\n",
    "- **0**: Point is on cluster boundary\n",
    "- **-1**: Point assigned to wrong cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Silhouette scores for different k\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    score = silhouette_score(X_scaled, labels)\n",
    "    silhouette_scores.append(score)\n",
    "    print(f\"k={k}: Silhouette Score = {score:.4f}\")\n",
    "\n",
    "optimal_k = k_range[np.argmax(silhouette_scores)]\n",
    "print(f\"\\nâœ¨ Optimal k = {optimal_k} (highest Silhouette Score)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Silhouette scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, silhouette_scores, 'go-', linewidth=2, markersize=10)\n",
    "plt.xlabel('Number of Clusters (k)', fontsize=12)\n",
    "plt.ylabel('Silhouette Score', fontsize=12)\n",
    "plt.title('Silhouette Analysis for Optimal k', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Mark optimal k\n",
    "plt.axvline(x=optimal_k, color='r', linestyle='--', \n",
    "            label=f'Optimal k={optimal_k}')\n",
    "plt.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** \n",
    "The highest Silhouette Score occurs at **k=2**, suggesting 2 clusters might be optimal from a separation perspective.\n",
    "\n",
    "Wait, why different from Elbow Method (k=3)? This is actually common! \n",
    "\n",
    "Let's visualize the detailed silhouette plot to understand better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed Silhouette plot for k=2 and k=3\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "for idx, k in enumerate([2, 3]):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Cluster the data\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Calculate silhouette values for each sample\n",
    "    silhouette_vals = silhouette_samples(X_scaled, labels)\n",
    "    avg_score = silhouette_score(X_scaled, labels)\n",
    "    \n",
    "    y_lower = 10\n",
    "    for i in range(k):\n",
    "        # Get silhouette values for cluster i\n",
    "        cluster_vals = silhouette_vals[labels == i]\n",
    "        cluster_vals.sort()\n",
    "        \n",
    "        size = cluster_vals.shape[0]\n",
    "        y_upper = y_lower + size\n",
    "        \n",
    "        color = plt.cm.viridis(float(i) / k)\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper), 0, cluster_vals,\n",
    "                         facecolor=color, edgecolor=color, alpha=0.7)\n",
    "        \n",
    "        # Label cluster\n",
    "        ax.text(-0.05, y_lower + 0.5 * size, f'C{i}')\n",
    "        y_lower = y_upper + 10\n",
    "    \n",
    "    ax.set_xlabel('Silhouette Coefficient', fontsize=12)\n",
    "    ax.set_ylabel('Cluster', fontsize=12)\n",
    "    ax.set_title(f'k={k}, Avg Score={avg_score:.3f}', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "    ax.axvline(x=avg_score, color='red', linestyle='--', linewidth=2)\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Observations:**\n",
    "\n",
    "- **k=2**: Higher average score, but treats 2 flower species as one group\n",
    "- **k=3**: Slightly lower score, but more aligned with actual data structure (3 species)\n",
    "\n",
    "This shows that **combining multiple methods is crucial!** Don't rely on just one metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Clustering Visualization\n",
    "\n",
    "Let's visualize the final clustering with k=3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final clustering with k=3\n",
    "kmeans_final = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "labels_final = kmeans_final.fit_predict(X_scaled)\n",
    "\n",
    "# Use first 2 features for visualization\n",
    "X_2d = X_scaled[:, :2]\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "scatter = plt.scatter(X_2d[:, 0], X_2d[:, 1], \n",
    "                     c=labels_final, cmap='viridis', \n",
    "                     s=100, alpha=0.6, edgecolors='black')\n",
    "\n",
    "# Plot centroids\n",
    "centroids = kmeans_final.cluster_centers_[:, :2]\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], \n",
    "           c='red', marker='X', s=300, \n",
    "           edgecolors='black', linewidths=2,\n",
    "           label='Centroids')\n",
    "\n",
    "plt.xlabel('Sepal Length (scaled)', fontsize=12)\n",
    "plt.ylabel('Sepal Width (scaled)', fontsize=12)\n",
    "plt.title('K-Means Clustering (k=3) on Iris Dataset', \n",
    "         fontsize=14, fontweight='bold')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we explored two fundamental methods for finding optimal cluster numbers:\n",
    "\n",
    "| Method | Optimal k | Interpretation |\n",
    "|--------|-----------|----------------|\n",
    "| Elbow Method | k=3 | Diminishing returns after k=3 |\n",
    "| Silhouette Analysis | k=2 | Best separation score |\n",
    "| **Domain Knowledge** | **k=3** | **3 flower species** |\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. âœ… **Always use multiple methods** - No single method is perfect\n",
    "2. âœ… **Consider domain knowledge** - Sometimes you know the expected number\n",
    "3. âœ… **Visualize your results** - Numbers alone don't tell the full story\n",
    "4. âœ… **Standardize your data** - Essential for distance-based clustering\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In the next posts, I'll cover:\n",
    "- Advanced validation metrics (Davies-Bouldin, Calinski-Harabasz, Gap Statistic)\n",
    "- Hierarchical clustering and dendrograms\n",
    "- Density-based methods (DBSCAN)\n",
    "\n",
    "Stay tuned! ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### References\n",
    "\n",
    "- Rousseeuw, P. J. (1987). Silhouettes: A graphical aid to the interpretation and validation of cluster analysis. *Journal of Computational and Applied Mathematics*, 20, 53-65.\n",
    "- Thorndike, R. L. (1953). Who belongs in the family? *Psychometrika*, 18(4), 267-276.\n",
    "\n",
    "### Code Repository\n",
    "\n",
    "Full code available on my [GitHub](https://github.com/yourusername/cluster-analysis-tutorials).\n",
    "\n",
    "---\n",
    "\n",
    "*Found this helpful? Leave a comment below or share with your network!* ðŸ’¬"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
