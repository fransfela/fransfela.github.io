<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Audio Quality Metrics: A Comprehensive Reference | Dr. Randy F Fela </title> <meta name="author" content="Randy F. Fela"> <meta name="description" content="Objective and subjective metrics for evaluating speech, music, and general audio quality with implementation resources"> <meta name="keywords" content="perception, audio-visual, research, data-science"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/blog/assets/img/bitmoji-closeup.png?abba4a3066d843d333ecf75654a92392"> <link rel="stylesheet" href="/blog/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://fransfela.github.io/blog/blog/2025/audio-quality-metrics-reference/"> <script src="/blog/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/blog/assets/js/distillpub/template.v2.js"></script> <script src="/blog/assets/js/distillpub/transforms.v2.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Audio Quality Metrics: A Comprehensive Reference",
            "description": "Objective and subjective metrics for evaluating speech, music, and general audio quality with implementation resources",
            "published": "January 13, 2025",
            "authors": [
              
              {
                "author": "Randy F. Fela",
                "authorURL": "https://fransfela.com",
                "affiliations": [
                  {
                    "name": "GN Group, Denmark",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/blog//"> Dr. Randy F Fela </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/blog/">üéß <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/about/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/zettelkasten/">Zettelkasten </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="nav-item active"> <a class="nav-link" href="/blog//id-id/blog/2025/audio-quality-metrics-reference/"> ID-ID</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Audio Quality Metrics: A Comprehensive Reference</h1> <p>Objective and subjective metrics for evaluating speech, music, and general audio quality with implementation resources</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#introduction">Introduction</a> </div> <div> <a href="#objective-metrics">Objective Metrics</a> </div> <ul> <li> <a href="#speech-quality">Speech Quality</a> </li> <li> <a href="#music-quality">Music Quality</a> </li> <li> <a href="#general-audio">General Audio</a> </li> </ul> <div> <a href="#subjective-metrics">Subjective Metrics</a> </div> <ul> <li> <a href="#mean-opinion-score-mos">Mean Opinion Score (MOS)</a> </li> <li> <a href="#mushra">MUSHRA</a> </li> </ul> <div> <a href="#implementation-resources">Implementation Resources</a> </div> <div> <a href="#references">References</a> </div> </nav> </d-contents> <blockquote> <p><strong>Last updated:</strong> January 13, 2025</p> </blockquote> <h2 id="introduction">Introduction</h2> <p>Audio quality evaluation is fundamental to developing, optimizing, and validating audio systems. This living reference covers both <strong>objective metrics</strong> (computational algorithms) and <strong>subjective metrics</strong> (human perception-based) used across speech, music, and general audio domains.</p> <blockquote> <p><strong>Last updated:</strong> January 13, 2025<br> <strong>Status:</strong> üü¢ Actively maintained</p> </blockquote> <hr> <h2 id="objective-metrics">Objective Metrics</h2> <p>Objective metrics provide automated, repeatable quality assessment without human listeners. These algorithms correlate with perceptual quality to varying degrees depending on the application.</p> <h3 id="speech-quality">Speech Quality</h3> <h4 id="pesq-perceptual-evaluation-of-speech-quality">PESQ (Perceptual Evaluation of Speech Quality)</h4> <p><strong>Description</strong><br> PESQ is a widely adopted objective metric for assessing speech quality in telecommunications. It compares a degraded speech signal against a reference to produce a quality score.</p> <p><strong>How It Works</strong></p> <ol> <li>Time-align reference and degraded signals</li> <li>Apply perceptual frequency weighting (Bark scale)</li> <li>Compute disturbance measures across time-frequency bins</li> <li>Map disturbances to MOS-LQO (Listening Quality Objective) score</li> </ol> <p><strong>Score Range</strong>: -0.5 to 4.5 (higher is better)</p> <p><strong>Use Cases</strong>: VoIP systems, telephony codecs, narrow-band speech (300‚Äì3400 Hz)</p> <p><strong>Limitations</strong>: Not suitable for music, wideband speech, or modern codecs with packet loss concealment</p> <p><strong>Open Libraries</strong></p> <ul> <li><a href="https://github.com/ludlows/python-pesq" rel="external nofollow noopener" target="_blank">PESQ Python wrapper</a></li> <li><a href="https://github.com/vBaiCai/python-pesq" rel="external nofollow noopener" target="_blank">pypesq</a></li> </ul> <p><strong>Datasets</strong></p> <ul> <li> <a href="https://www.itu.int/rec/T-REC-P.Sup23" rel="external nofollow noopener" target="_blank">ITU-T P.Sup23 Database</a> (subjective test results)</li> <li> <a href="https://ecs.utdallas.edu/loizou/speech/noizeus/" rel="external nofollow noopener" target="_blank">NOIZEUS Speech Corpus</a> (noisy speech for testing)</li> </ul> <p><strong>References</strong></p> <ul> <li><a href="https://www.itu.int/rec/T-REC-P.862" rel="external nofollow noopener" target="_blank">ITU-T Recommendation P.862</a></li> <li>Rix, A. W., et al. (2001). <a href="https://ieeexplore.ieee.org/document/941023" rel="external nofollow noopener" target="_blank">Perceptual evaluation of speech quality (PESQ) ‚Äì a new method for speech quality assessment</a> </li> </ul> <div class="l-page"> <iframe src="https://www.itu.int/rec/T-REC-P.862" frameborder="0" scrolling="yes" height="600px" width="100%"></iframe> </div> <hr> <h4 id="polqa-perceptual-objective-listening-quality-assessment">POLQA (Perceptual Objective Listening Quality Assessment)</h4> <p><strong>Description</strong><br> POLQA is the successor to PESQ, designed for modern telecommunications including super-wideband (50‚Äì14000 Hz) and HD voice applications.</p> <p><strong>How It Works</strong></p> <ol> <li>Extract perceptual features from reference and degraded signals</li> <li>Apply advanced time-alignment algorithms (handles delays, time warping)</li> <li>Compute disturbance densities across frequency bands</li> <li>Map to MOS-LQO using optimized neural network model</li> </ol> <p><strong>Score Range</strong>: 1.0 to 4.5 (MOS scale)</p> <p><strong>Use Cases</strong>: VoLTE, HD voice, wideband/super-wideband speech, 3G/4G/5G networks</p> <p><strong>Advantages Over PESQ</strong>: Better correlation with subjective quality for modern codecs, handles time-varying delays</p> <p><strong>Open Libraries</strong><br> POLQA is proprietary. Reference implementation available through <a href="https://www.opticom.de/products/polqa/" rel="external nofollow noopener" target="_blank">OPTICOM GmbH</a></p> <p><strong>Datasets</strong></p> <ul> <li><a href="https://www.itu.int/rec/T-REC-P.Sup23" rel="external nofollow noopener" target="_blank">ITU-T P.Sup23 Database</a></li> <li> <a href="https://sigmedia.tcd.ie/TCDVOIP/" rel="external nofollow noopener" target="_blank">TCD-VoIP Database</a> (VoIP quality assessment)</li> </ul> <p><strong>References</strong></p> <ul> <li><a href="https://www.itu.int/rec/T-REC-P.863" rel="external nofollow noopener" target="_blank">ITU-T Recommendation P.863</a></li> <li>Beerends, J. G., et al. (2013). <a href="https://www.opticom.de/download/polqa_aes_paper.pdf" rel="external nofollow noopener" target="_blank">Perceptual Objective Listening Quality Assessment (POLQA)</a> </li> </ul> <hr> <h4 id="stoi-short-time-objective-intelligibility">STOI (Short-Time Objective Intelligibility)</h4> <p><strong>Description</strong><br> STOI predicts speech intelligibility (how well speech can be understood) rather than quality. Particularly useful for hearing aid and noise suppression algorithm evaluation.</p> <p><strong>How It Works</strong></p> <ol> <li>Divide signals into short-time frames (384 ms analysis window)</li> <li>Compute one-third octave band representation</li> <li>Calculate correlation between clean and processed speech in each band</li> <li>Average correlations to produce intelligibility score</li> </ol> <p><strong>Score Range</strong>: 0 to 1 (higher indicates better intelligibility)</p> <p><strong>Use Cases</strong>: Hearing aids, noise reduction, speech enhancement, cochlear implants</p> <p><strong>Why Use STOI</strong>: Outperforms PESQ and other quality metrics for intelligibility prediction in noisy/reverberant conditions</p> <p><strong>Open Libraries</strong></p> <ul> <li><a href="https://github.com/mpariente/pystoi" rel="external nofollow noopener" target="_blank">pystoi (Python)</a></li> <li><a href="https://github.com/ceestkaal/matlab_code" rel="external nofollow noopener" target="_blank">STOI MATLAB</a></li> </ul> <p><strong>Datasets</strong></p> <ul> <li> <a href="http://www.ah-andersen.net/hurricane-challenge/" rel="external nofollow noopener" target="_blank">Hurricane Challenge Database</a> (noisy speech intelligibility)</li> <li><a href="https://catalog.ldc.upenn.edu/LDC93S1" rel="external nofollow noopener" target="_blank">TIMIT Acoustic-Phonetic Corpus</a></li> </ul> <p><strong>References</strong></p> <ul> <li>Taal, C. H., et al. (2011). <a href="https://ieeexplore.ieee.org/document/5713237" rel="external nofollow noopener" target="_blank">An Algorithm for Intelligibility Prediction of Time-Frequency Weighted Noisy Speech</a> </li> </ul> <hr> <h3 id="music-quality">Music Quality</h3> <h4 id="peaq-perceptual-evaluation-of-audio-quality">PEAQ (Perceptual Evaluation of Audio Quality)</h4> <p><strong>Description</strong><br> PEAQ is the ITU-R standard for objective assessment of perceived audio quality, specifically designed for evaluating lossy audio codecs.</p> <p><strong>How It Works</strong></p> <ol> <li>Apply peripheral ear model (converts signal to internal representation)</li> <li>Extract perceptual features: loudness, modulation, harmonic structure</li> <li>Compute Model Output Variables (MOVs) capturing perceived distortion</li> <li>Map MOVs to Objective Difference Grade (ODG) using neural network</li> </ol> <p><strong>Score Range</strong>: 0 (imperceptible) to -4 (very annoying)</p> <p><strong>Use Cases</strong>: Codec evaluation (MP3, AAC, Opus), audio streaming quality, archival systems</p> <p><strong>Open Libraries</strong></p> <ul> <li><a href="https://github.com/HSU-ANT/gstpeaq" rel="external nofollow noopener" target="_blank">GstPEAQ (GStreamer plugin)</a></li> <li><a href="https://github.com/sergiogcharles/PEAQ" rel="external nofollow noopener" target="_blank">PEAQ implementation research code</a></li> </ul> <p><strong>Datasets</strong></p> <ul> <li><a href="https://tech.ebu.ch/publications/sqamcd" rel="external nofollow noopener" target="_blank">EBU SQAM (Sound Quality Assessment Material)</a></li> <li><a href="https://code.soundsoftware.ac.uk/projects/audio-degradation-toolbox" rel="external nofollow noopener" target="_blank">Audio Degradation Toolbox</a></li> </ul> <p><strong>References</strong></p> <ul> <li><a href="https://www.itu.int/rec/R-REC-BS.1387/" rel="external nofollow noopener" target="_blank">ITU-R Recommendation BS.1387-1</a></li> <li>Thiede, T., et al. (2000). <a href="https://www.aes.org/e-lib/browse.cfm?elib=12078" rel="external nofollow noopener" target="_blank">PEAQ ‚Äì The ITU Standard for Objective Measurement of Perceived Audio Quality</a> </li> </ul> <hr> <h3 id="general-audio">General Audio</h3> <h4 id="snr-signal-to-noise-ratio">SNR (Signal-to-Noise Ratio)</h4> <p><strong>Description</strong><br> SNR measures the ratio between desired signal power and background noise power. Simple but widely used baseline metric.</p> <p><strong>How It Works</strong></p> <ol> <li>Compute power of signal: ( P_{signal} )</li> <li>Compute power of noise: ( P_{noise} )</li> <li>Calculate ratio: ( SNR = 10 \log_{10} \frac{P_{signal}}{P_{noise}} ) (dB)</li> </ol> <p><strong>Score Range</strong>: Typically 0 to 100+ dB (higher is better)</p> <p><strong>Use Cases</strong>: Audio system characterization, codec benchmarking, microphone testing</p> <p><strong>Limitations</strong>: Poor correlation with perceptual quality; does not account for frequency masking, distortion type</p> <p><strong>Open Libraries</strong><br> Standard signal processing libraries (NumPy, SciPy, MATLAB Signal Processing Toolbox)</p> <p><strong>References</strong></p> <ul> <li>Cherry, E. C. (1957). <a href="https://mitpress.mit.edu/9780262530606/on-human-communication/" rel="external nofollow noopener" target="_blank">On Human Communication</a> </li> </ul> <hr> <h2 id="subjective-metrics">Subjective Metrics</h2> <p>Subjective metrics involve human listeners rating audio quality under controlled conditions. These remain the gold standard for quality assessment.</p> <h3 id="mean-opinion-score-mos">Mean Opinion Score (MOS)</h3> <p><strong>Description</strong><br> MOS is the most fundamental subjective quality metric. Listeners rate audio samples on a discrete scale, and scores are averaged.</p> <p><strong>How It Works</strong></p> <ol> <li>Recruit representative listener panel (minimum 24 listeners per ITU-T P.800)</li> <li>Present stimuli in controlled listening environment</li> <li>Listeners rate quality on 5-point scale: <ul> <li>5: Excellent</li> <li>4: Good</li> <li>3: Fair</li> <li>2: Poor</li> <li>1: Bad</li> </ul> </li> <li>Compute mean and confidence intervals</li> </ol> <p><strong>Test Methods</strong></p> <ul> <li> <strong>ACR (Absolute Category Rating)</strong>: Rate single stimulus without reference</li> <li> <strong>DCR (Degradation Category Rating)</strong>: Rate degradation relative to reference</li> <li> <strong>CCR (Comparison Category Rating)</strong>: Compare two processed versions</li> </ul> <p><strong>Use Cases</strong>: Codec validation, system benchmarking, research studies</p> <p><strong>Standards</strong></p> <ul> <li><a href="https://www.itu.int/rec/T-REC-P.800" rel="external nofollow noopener" target="_blank">ITU-T Recommendation P.800</a></li> <li> <a href="https://www.itu.int/rec/T-REC-P.805" rel="external nofollow noopener" target="_blank">ITU-T Recommendation P.805</a> (conversational tests)</li> </ul> <p><strong>Open Tools</strong></p> <ul> <li> <a href="https://github.com/HSU-ANT/beaqlejs" rel="external nofollow noopener" target="_blank">BeaqleJS</a> (browser-based listening test framework)</li> <li><a href="https://github.com/audiolabs/webMUSHRA" rel="external nofollow noopener" target="_blank">webMUSHRA</a></li> </ul> <p><strong>Datasets With MOS Scores</strong></p> <ul> <li> <a href="https://github.com/gabrielmittag/NISQA" rel="external nofollow noopener" target="_blank">NISQA Corpus</a> (speech quality with MOS)</li> <li><a href="https://www.itu.int/rec/T-REC-P.Sup23" rel="external nofollow noopener" target="_blank">P.SAMOLED Database</a></li> </ul> <hr> <h3 id="mushra-multiple-stimuli-with-hidden-reference-and-anchor">MUSHRA (Multiple Stimuli with Hidden Reference and Anchor)</h3> <p><strong>Description</strong><br> MUSHRA is an advanced subjective test method for evaluating intermediate to high-quality audio systems where small differences matter.</p> <p><strong>How It Works</strong></p> <ol> <li>Present hidden reference (unprocessed), multiple test conditions, and anchor (degraded reference)</li> <li>Listeners rate all stimuli on continuous 0-100 scale</li> <li>Hidden reference identifies unreliable listeners (should score near 100)</li> <li>Anchor (typically 3.5 kHz low-pass) sets lower quality bound</li> </ol> <p><strong>Score Range</strong>: 0 to 100 (continuous scale)</p> <p><strong>Use Cases</strong>: Codec comparison (Opus, AAC variants), spatial audio evaluation, high-quality audio processing</p> <p><strong>Advantages</strong>: Detects small quality differences, includes validity checks (hidden reference/anchor)</p> <p><strong>Standards</strong></p> <ul> <li><a href="https://www.itu.int/rec/R-REC-BS.1534/" rel="external nofollow noopener" target="_blank">ITU-R Recommendation BS.1534-3</a></li> </ul> <p><strong>Open Tools</strong></p> <ul> <li> <a href="https://github.com/audiolabs/webMUSHRA" rel="external nofollow noopener" target="_blank">webMUSHRA</a> (full implementation)</li> <li> <a href="https://github.com/HSU-ANT/beaqlejs" rel="external nofollow noopener" target="_blank">BeaqleJS</a> (supports MUSHRA-like tests)</li> </ul> <p><strong>References</strong></p> <ul> <li><a href="https://www.itu.int/rec/R-REC-BS.1534/" rel="external nofollow noopener" target="_blank">ITU-R BS.1534-3 Specification</a></li> </ul> <hr> <h2 id="implementation-resources">Implementation Resources</h2> <h3 id="open-source-toolkits">Open-Source Toolkits</h3> <p><strong>Python</strong></p> <ul> <li> <a href="https://github.com/tyiannak/pyAudioAnalysis" rel="external nofollow noopener" target="_blank">PyAudioAnalysis</a>: Feature extraction and classification</li> <li> <a href="https://librosa.org/" rel="external nofollow noopener" target="_blank">librosa</a>: Music and audio analysis</li> <li> <a href="https://github.com/mpariente/pystoi" rel="external nofollow noopener" target="_blank">pystoi</a>: STOI implementation</li> <li> <a href="https://github.com/ludlows/python-pesq" rel="external nofollow noopener" target="_blank">python-pesq</a>: PESQ wrapper</li> </ul> <p><strong>MATLAB</strong></p> <ul> <li> <a href="http://amtoolbox.org/" rel="external nofollow noopener" target="_blank">Auditory Modeling Toolbox</a>: Comprehensive psychoacoustic models</li> <li> <a href="https://github.com/andresperezlopez/pemo-q" rel="external nofollow noopener" target="_blank">PEMO-Q</a>: Perceptual evaluation model</li> </ul> <p><strong>Web-Based</strong></p> <ul> <li> <a href="https://github.com/HSU-ANT/beaqlejs" rel="external nofollow noopener" target="_blank">BeaqleJS</a>: Browser listening tests</li> <li> <a href="https://github.com/audiolabs/webMUSHRA" rel="external nofollow noopener" target="_blank">webMUSHRA</a>: Online MUSHRA tests</li> </ul> <h3 id="public-datasets">Public Datasets</h3> <table> <thead> <tr> <th>Dataset</th> <th>Domain</th> <th>MOS Available</th> <th>Size</th> <th>Access</th> </tr> </thead> <tbody> <tr> <td><a href="https://github.com/gabrielmittag/NISQA" rel="external nofollow noopener" target="_blank">NISQA Corpus</a></td> <td>Speech</td> <td>‚úÖ</td> <td>14K samples</td> <td>Open</td> </tr> <tr> <td><a href="https://ecs.utdallas.edu/loizou/speech/noizeus/" rel="external nofollow noopener" target="_blank">NOIZEUS</a></td> <td>Noisy Speech</td> <td>‚úÖ</td> <td>30 speakers</td> <td>Open</td> </tr> <tr> <td><a href="https://tech.ebu.ch/publications/sqamcd" rel="external nofollow noopener" target="_blank">EBU SQAM</a></td> <td>Music</td> <td>‚ùå</td> <td>71 tracks</td> <td>Open</td> </tr> <tr> <td><a href="https://catalog.ldc.upenn.edu/LDC93S1" rel="external nofollow noopener" target="_blank">TIMIT</a></td> <td>Speech</td> <td>‚ùå</td> <td>6.3K utterances</td> <td>Licensed</td> </tr> <tr> <td><a href="https://github.com/microsoft/DNS-Challenge" rel="external nofollow noopener" target="_blank">DNS Challenge</a></td> <td>Speech Enhancement</td> <td>Varies</td> <td>500+ hours</td> <td>Open</td> </tr> </tbody> </table> <hr> <h2 id="when-to-use-what">When to Use What</h2> <div class="fake-img l-body"> <table style="width: 100%; border-collapse: collapse;"> <thead> <tr style="background-color: var(--global-theme-color); color: white;"> <th style="padding: 0.75rem; text-align: left;">Metric</th> <th style="padding: 0.75rem; text-align: center;">Speech</th> <th style="padding: 0.75rem; text-align: center;">Music</th> <th style="padding: 0.75rem; text-align: center;">Real-time</th> <th style="padding: 0.75rem; text-align: center;">Training Data</th> </tr> </thead> <tbody> <tr> <td style="padding: 0.75rem; border-bottom: 1px solid var(--global-divider-color);">PESQ</td> <td style="padding: 0.75rem; text-align: center; border-bottom: 1px solid var(--global-divider-color);">‚úÖ</td> <td style="padding: 0.75rem; text-align: center; border-bottom: 1px solid var(--global-divider-color);">‚ùå</td> <td style="padding: 0.75rem; text-align: center; border-bottom: 1px solid var(--global-divider-color);">‚úÖ</td> <td style="padding: 0.75rem; text-align: center; border-bottom: 1px solid var(--global-divider-color);">‚ùå</td> </tr> <tr> <td style="padding: 0.75rem; border-bottom: 1px solid var(--global-divider-color);">POLQA</td> <td style="padding: 0.75rem; text-align: center; border-bottom: 1px solid var(--global-divider-color);">‚úÖ</td> <td style="padding: 0.75rem; text-align: center; border-bottom: 1px solid var(--global-divider-color);">‚ùå</td> <td style="padding: 0.75rem; text-align: center; border-bottom: 1px solid var(--global-divider-color);">‚úÖ</td> <td style="padding: 0.75rem; text-align: center; border-bottom: 1px solid var(--global-divider-color);">‚ùå</td> </tr> <tr> <td style="padding: 0.75rem; border-bottom: 1px solid var(--global-divider-color);">STOI</td> <td style="padding: 0.75rem; text-align: center; border-bottom: 1px solid var(--global-divider-color);">‚úÖ</td> <td style="padding: 0.75rem; text-align: center; border-bottom: 1px solid var(--global-divider-color);">‚ùå</td> <td style="padding: 0.75rem; text-align: center; border-bottom: 1px solid var(--global-divider-color);">‚úÖ</td> <td style="padding: 0.75rem; text-align: center; border-bottom: 1px solid var(--global-divider-color);">‚ùå</td> </tr> <tr> <td style="padding: 0.75rem; border-bottom: 1px solid var(--global-divider-color);">PEAQ</td> <td style="padding: 0.75rem; text-align: center; border-bottom: 1px solid var(--global-divider-color);">‚ùå</td> <td style="padding: 0.75rem; text-align: center; border-bottom: 1px solid var(--global-divider-color);">‚úÖ</td> <td style="padding: 0.75rem; text-align: center; border-bottom: 1px solid var(--global-divider-color);">‚ùå</td> <td style="padding: 0.75rem; text-align: center; border-bottom: 1px solid var(--global-divider-color);">‚ùå</td> </tr> <tr> <td style="padding: 0.75rem; border-bottom: 1px solid var(--global-divider-color);">MOS</td> <td style="padding: 0.75rem; text-align: center; border-bottom: 1px solid var(--global-divider-color);">‚úÖ</td> <td style="padding: 0.75rem; text-align: center; border-bottom: 1px solid var(--global-divider-color);">‚úÖ</td> <td style="padding: 0.75rem; text-align: center; border-bottom: 1px solid var(--global-divider-color);">‚ùå</td> <td style="padding: 0.75rem; text-align: center; border-bottom: 1px solid var(--global-divider-color);">‚úÖ</td> </tr> <tr> <td style="padding: 0.75rem;">MUSHRA</td> <td style="padding: 0.75rem; text-align: center;">‚úÖ</td> <td style="padding: 0.75rem; text-align: center;">‚úÖ</td> <td style="padding: 0.75rem; text-align: center;">‚ùå</td> <td style="padding: 0.75rem; text-align: center;">‚úÖ</td> </tr> </tbody> </table> </div> <hr> <h2 id="changelog">Changelog</h2> <ul> <li> <strong>2025-01-13</strong>: Initial comprehensive version with implementation resources</li> <li> <strong>[Upcoming]</strong>: Add deep learning based metrics (DNSMOS, ViSQOL)</li> </ul> <hr> <p style="text-align: center; margin-top: 3rem; font-style: italic; color: var(--global-text-color-light);"> Found an error or want to suggest an addition? <a href="mailto:randyrff@gmail.com">Let me know</a>. </p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/blog/assets/bibliography/"></d-bibliography> <d-article> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <h2 class="text-3xl font-semibold mb-4 mt-12"></h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://fransfela.substack.com/p/sound-horeg-antara-euforia-budaya" target="_blank" rel="external nofollow noopener">Just a moment...</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/mentoring-bang-randy-scholarship-guidance/">MentoringBangRandy: Perjalanan dari Kuli Pabrik ke Denmark</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2025/book-soundscape-analysis/">Soundscape (Bentang Suara): Teori, Metode, dan Analisis</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2024/megatrends-sound-industry-workshop-reflection/">Megatrends in Sound: AI, Competition, and What's Next for Audio</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2024/optimal-clustering-part3-alternative-approaches/">Finding the Optimal Number of Clusters: Part 3 - Alternative Approaches &amp; Practical Guide</a> </li> <br> <br> </d-article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬©Copyright 2026 Randy F. Fela. | All rights reserved | Built with <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> and <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a> | <a href="/mentoring/">Mentoring Services</a> | Copenhagen, Denmark </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script src="/blog/assets/js/distillpub/overrides.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"> <div class="modal-footer" slot="footer"> <span class="help"> <svg version="1.0" class="ninja-examplekey" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 1280 1280"> <path d="M1013 376c0 73.4-.4 113.3-1.1 120.2a159.9 159.9 0 0 1-90.2 127.3c-20 9.6-36.7 14-59.2 15.5-7.1.5-121.9.9-255 1h-242l95.5-95.5 95.5-95.5-38.3-38.2-38.2-38.3-160 160c-88 88-160 160.4-160 161 0 .6 72 73 160 161l160 160 38.2-38.3 38.3-38.2-95.5-95.5-95.5-95.5h251.1c252.9 0 259.8-.1 281.4-3.6 72.1-11.8 136.9-54.1 178.5-116.4 8.6-12.9 22.6-40.5 28-55.4 4.4-12 10.7-36.1 13.1-50.6 1.6-9.6 1.8-21 2.1-132.8l.4-122.2H1013v110z"></path> </svg> to select </span> <span class="help"> <svg xmlns="http://www.w3.org/2000/svg" class="ninja-examplekey" viewbox="0 0 24 24"> <path d="M0 0h24v24H0V0z" fill="none"></path> <path d="M20 12l-1.41-1.41L13 16.17V4h-2v12.17l-5.58-5.59L4 12l8 8 8-8z"></path> </svg> <svg xmlns="http://www.w3.org/2000/svg" class="ninja-examplekey" viewbox="0 0 24 24"> <path d="M0 0h24v24H0V0z" fill="none"></path> <path d="M4 12l1.41 1.41L11 7.83V20h2V7.83l5.58 5.59L20 12l-8-8-8 8z"></path> </svg> to navigate </span> <span class="help"> <span class="ninja-examplekey esc">esc</span> to close </span> <span class="help"> <svg xmlns="http://www.w3.org/2000/svg" class="ninja-examplekey backspace" viewbox="0 0 20 20" fill="currentColor"> <path fill-rule="evenodd" d="M6.707 4.879A3 3 0 018.828 4H15a3 3 0 013 3v6a3 3 0 01-3 3H8.828a3 3 0 01-2.12-.879l-4.415-4.414a1 1 0 010-1.414l4.414-4.414zm4 2.414a1 1 0 00-1.414 1.414L10.586 10l-1.293 1.293a1 1 0 101.414 1.414L12 11.414l1.293 1.293a1 1 0 001.414-1.414L13.414 10l1.293-1.293a1 1 0 00-1.414-1.414L12 8.586l-1.293-1.293z" clip-rule="evenodd"></path> </svg> move to parent </span> </div> </ninja-keys> <script src="/blog/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>